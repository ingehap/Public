ToDo

- rydde
- Harald
- SR
- anisotropy


AutoML
- [x] Start a to-do list
- [ ] https://github.com/DeepBlueAI/AutoSmart
- [ ] https://github.com/automl/auto-sklearn
- [ ] https://ml4aad.org/automl/
- [ ] http://www.chalearn.org/
- [ ] https://codalab.lisn.upsaclay.fr/
- [ ] https://groups.google.com/g/codalab-competitions
- [ ] https://codalab.lisn.upsaclay.fr/
- [ ] https://autodl.chalearn.org/
- [ ] https://blog.neurips.cc/
- [ ] https://neurips.cc/
- [ ] http://ciml.chalearn.org/
- [ ] http://www.cs.ubc.ca/labs/beta/Projects/SMAC/
- [ ] https://competitions.codalab.org/competitions/2321
- [ ] https://competitions.codalab.org/competitions/17767
- [ ] https://competitions.codalab.org/competitions/19836
- [ ] https://automl.chalearn.org/
- [ ] https://icml.cc/
- [ ] https://www.automl.ai/
- [ ] http://www.cs.ubc.ca/labs/beta/Projects/autoweka/
- [ ] https://icaps21.icaps-conference.org/home/
- [ ] 
Buy?
- [ ] https://remarkable.com/
- [ ] Rucksack, amazon
- [ ] Mac, Developer
Data, Every Saturday
- [ ] https://live.euronext.com/nb/markets/oslo/equities/list
Education
- [ ] https://www.edureka.co/
- [ ] https://github.com/collections/learn-to-code
- [ ] 


Feature Extraction Foundations and Applications Series: Studies in Fuzziness and Soft Computing , Vol. 207, Guyon, I.; Gunn, S.; Nikravesh, M.; Zadeh, L.A. (Eds.), Springer, 2006


- Chatterji, S.D. 1994. The Mathematical Work of Norbert Wiener (1894–1964). Kybernetes 26 (6/7). p. 34.
- Conway, F. & Siegelman, J. 2005. Dark Hero of the Information Age. Basic Books.
- Dyson, F. 2005. The Tragic Tale of a Genius. The New York Review of Books.
- Dyson, G. 2012. Turing’s Cathedral. Pantheon Books. New York, NY.
- Heims, S.J. 1980. John von Neumann and Norbert Wiener. The MIT Press.
- Kranz, S.G. 2001. Mathmatical Anecdotes in Mathematical Conversations: Selections from the Mathematical Intelligencer by Wilson & Gray. Springer-Verlag, New York, NY.
- Montagnini, L. 2017.Harmonies of Disorder. Springer.
- Nasar, S. 1998. A Beautiful Mind. Simon & Schuster.
- Wiener, N. 1953. Ex-prodigy. The MIT Press

- 
To create a project:

1. Go to your projects tab. Jump to your projects tab in Neptune ->
2. Click on the ‘New project’ button
3. Choose a name
4. Click Save and you project is ready to use!
You can now create experiments in your new project by changing the `project` in your `neptune.init()` method. 
```
import neptune.new as neptune

run = neptune.init(api_token='<your_api_token>',
                   project='<your_project_name>')
```

https://en.wikipedia.org/wiki/QEMSCAN
https://en.wikipedia.org/wiki/Total_organic_carbon

Jeg fikk en aha-opplevelse i Fugur 10 av Lasabusa et al., «Cenozoic uplift and erosion of the Norwegian Barents Shelf – A review": Skjæring med Dybde-aksen i Dybdetrend for vitrinitt gir netto erosjon: 



Sulfate-reducing bacteria streamers and iron sulfides rapidly occlude porosity and increase hydraulic resistance in proppant-filled shale fractures

BW Fouke, AS Bhattacharjee, GA Fried, M Sivaguru… - AAPG Bulletin, 2021


The salinity dependence of electrical conductivity and Archie's cementation exponent in shale formations

Z Zhong, R Rezaee, M Josh, L Esteban… - Journal of Petroleum …, 2021



https://www.gutenberg.org/
https://doi.org/10.6084/m9.figshare.13040516
https://github.com/merely-useful/py-rse

Inversion software
pyGIMLi - www.pygimli.org
ResIPy - gitlab/hkex/resipy
SimPEG - github.com/simpeg/simpeg

df.columns.tolist()
df2 = df[['A','B']].copy()

import time
time.sleep(2)

pip freeze >> requirements.txt
pip install -r requirements.txt

import calendar
calendar.prmonth(2022, 5)

import psutil as ps
m = ps.virtual_memory()
m.used / m.total

Windows and the conda command isn’t available at the Bash shell, you’ll need to open the Anaconda Prompt program (via the Windows start menu) and run the command conda init bash

If we want to set some variables automatically every time we run a shell, we can put commands to do this in a file called .bashrc in our home directory. For example, here are two lines in /Users/amira/.bashrc: 
export DEPARTMENT="Library Science"

pwd
touch my_file.txt
whoami

nano draft.txt
save the file with Ctrl+O and exit with Ctrl+X

run the command set and look at some of the variables the shell defines

https://stackoverflow.com/questions/tagged/bash 
https://www.gnu.org/manual/manual.html  
https://www.gnu.org/software/coreutils/manual/coreutils.html

When a computer runs a program—any program—it creates a process in memory to hold the program’s instructions and data. Every process in Unix has an input channel called standard input and an output channel called standard output.

Ctrl+D to signal the end of input.
Ctrl+C to interrupt programs that are taking a long time

The uniq command has a -c option which gives a count of the number of times a line occurs in its input

redirect standard output with >, we can connect standard input to a file using <

cut -d, -f 2 titles.txt

For our first command, let’s run «find . « to find and list everything in this directory

every process has a second output channel called standard error (or stderr). Programs use it for error messages

uniq removes adjacent duplicated lines from its input

https://tldr.sh/

command grep finds and prints lines that match a pattern

The wc command (short for word count) tells us how many lines, words, and letters there are in one file

https://carpentries.github.io/workshop-template/#setup

make on Windows
https://ubc-mds.github.io/resources_pages/install_ds_stack_windows/

https://github.com/merely-useful/py-rse/blob/book/CONTRIBUTING.md
https://github.com/merely-useful/py-rse/blob/book/CONDUCT.md
https://github.com/merely-useful/py-rse/blob/book/LICENSE.md 
https://creativecommons.org/licenses/by/4.0/
https://github.com/merely-useful/py-rse/blob/book/LICENSE-MIT.md 

https://carpentries.org/ 
https://www.insightdatascience.com/ 
http://swcarpentry.github.io/shell-novice/ 
http://swcarpentry.github.io/git-novice/ 
https://uw-madison-datascience.github.io/git-novice-custom/ 
http://swcarpentry.github.io/make-novice/ 
https://github.com/ljdursi/make_pattern_rules 
https://python-102.readthedocs.io/
https://en.wikipedia.org/wiki/Zipf%27s_law

1.6 Key Points • Make tidiness a habit, rather than cleaning up your project files later. • Include a few standard files in all your projects, such as README, LICENSE, CONTRIBUTING, CONDUCT and CITATION. • Put runnable code in a bin/ directory. • Put raw/original data in a data/ directory and never modify it. • Put results in a results/ directory. This includes cleaned-up data and figures (i.e., everything created using what’s in bin and data). • Put documentation and manuscripts in a docs/ directory. • Refer to The Carpentries software installation guide7 if you’re having trouble.

history | tail -n 5 > recent.sh

3.9 Key Points 
• cat displays the contents of its inputs. 
• head displays the first few lines of its input. 
• tail displays the last few lines of its input. 
• sort sorts its inputs. 
• Use the up-arrow key to scroll up through previous commands to edit and repeat them. 
• Use history to display recent commands and !number to repeat a command by number. 
• Every process in Unix has an input channel called standard input and an output channel called standard output. 
• > redirects a command’s output to a file, overwriting any existing content. 
• >> appends a command’s output to a file. 
• < operator redirects input to a command. 
• A pipe | sends the output of the command on the left to the input of the command on the right. 
• A for loop repeats commands once for every thing in a list. 
• Every for loop must have a variable to refer to the thing it is currently operating on and a body containing commands to execute. 
• Use $name or ${name} to get the value of a variable.


Jonathan Haidt, The Righteous Mind: Why Good People Are Divided by Politics and Religion (New York: Pantheon, 2012).

Ronald L. Numbers and Kostas Kampourakis, eds., Newton’s Apple and Other Myths About Science (Cambridge, MA: Harvard University Press, 2015)

Galileo Goes to Jail and Other Myths about Science and Religion, ed. Ronald L. Numbers

Richard Buxton, ed., From Myth To Reason? Studies in the Development of Greek Thought (Oxford: Oxford University Press, 2001)

Jeff Hardin, Ronald L. Numbers, and Ronald A. Binzley, eds., The Warfare Between Science and Religion: The Idea That Wouldn’t Die (Baltimore: Johns Hopkins University Press, 2018)

Robert John Russell, ed., Fifty Years in Science and Religion: Ian G. Barbour and His Legacy

Francis Schaeffer, Escape From Reason (London: Inter-Varsity Press, 1968)

Francis Fukuyama, The End of History and the Last Man (New York: Free Press, 1992)

Charles Taylor, Malaise of Modernity (Toronto: House of Anansi Press, 1991); Taylor, A Secular Age (Cambridge, MA: Belknap Press of Harvard University Press, 2007)

Augusto Del Noce, The Crisis of Modernity,
Augusto Del Noce, The Age of Secularization,

https://lnkd.in/dAVw3KVt

 Discover what is optimization and concepts related to it:
 >> A Gentle Introduction to Optimization / Mathematical Programming
 Discover the method of Lagrange multipliers:
 >> A Gentle Introduction To Method Of Lagrange Multipliers
 Discover the chain rule of calculus for univariate and multivariate functions:
 >> The Chain Rule of Calculus for Univariate and Multivariate Functions
 Discover the Jacobian:
 >> A Gentle Introduction to the Jacobian
  Discover the Hessian matrices, and their significance:
 >> A Gentle Introduction To Hessian Matrices
  Discover a gentle introduction to the Laplacian:
 >> A Gentle Introduction to the Laplacian

                                           Revisit the Fundamental Theorem of Linear Algebra
Read more » 
Efficient Hyperparameter Optimization for Differentially Private Deep   Learning
Read more » 

Bayesian Deep Learning for Partial Differential Equation Parameter   Discovery with Sparse and Noisy Data
Read more » 

A Decentralized Federated Learning Framework via Committee Mechanism   with Convergence Guarantee
Read more » 

Explore the past 30+ years of data science and A.I. research
Explore » 



[PDF]An Enquiry on similarities between Renormalization Group and Auto-Encoders using Transfer Learning

M Shukla, AD Thakur - arXiv preprint arXiv:2108.06157, 2021


Discrete shallow water equations preserving symmetries and conservation laws

VA Dorodnitsyn, EI Kaptsov - Journal of Mathematical Physics, 2021

 Discover how to apply the chain rule of calculus to challenging functions:
 >> The Chain Rule of Calculus – Even More Functions
  Discover Taylor series and how to approximate the values of a function:
 >> A Gentle Introduction to Taylor Series
  Discover what is approximation and its importance in machine learning:
 >> A Gentle Introduction To Approximation

 Discover how aspects of calculus are applied in neural networks:
 >> Calculus in Action: Neural Networks
  Discover the sigmoid function and its role in learning from examples in neural networks:
 >> A Gentle Introduction To Sigmoid Function
  Discover the method of Lagrange multipliers applied to find the local minimum or maximum of a function:
 >> Lagrange Multiplier Approach with Inequality Constraints


QuTiP
https://hackmd.io/@nordic-rse/unconference

# Coding Tips

[Zulip](https://coderefinery.zulipchat.com/#)

NUMFOCUS

OpenBLAS

AstroPy

arXiv:1912.02894

qosf.org/project-list/

qutip.org/tutorials
qutip.org/devs

DIPPY

Nilearn

NUMFOCUS

github.com/qutip/governance

[Google Summer of Code](https://summerofcode.withgoogle.com/archive7)

https://github.com/andrewdarmawan/tncontract

https://github.com/nathanshammah/pigs

https://github.com/pyquantum/matsubara

https://github.com/qucontrol/krotov

https://github.com/qgrad/qgrad

https://github.com/tehruhn/bofin


1. General 

https://libraries.io/
https://packaging.python.org/guides/analyzing-pypi-package-downloads/
https://studylib.net/

2. Specific libraries

auto-sklearn
           https://github.com/automl/auto-sklearn

automl
          https://github.com/automl/auto-sklearn

chronolog
	https://pypi.org/project/chronolog/
	3d automated well-log correlation

gplearn
	Advantage of symbolic regression
		White box as opposed to black box
	Documentation
		https://gplearn.readthedocs.io/en/stable/
		https://gplearn.readthedocs.io/en/stable/reference.html
	References
		Wang, Symbolic regression in materials science; https://arxiv.org/abs/1901.04136
	1D Example
		Test1-gplearn1D.ipynbz

nltk
	import nltk
	print('The nltk version is {}.'.format(nltk.__version__))
	
```
import sklearn
print('The scikit-learn version is {}.'.format(sklearn.__version__))
```


os
	# Useful for error checking
	print('getcwd:      ', os.getcwd())
	print('__file__:    ', __file__)

PID
	https://github.com/equinor/PID
	
PIDid
	https://github.com/equinor/PIDid

pyKrieging
          http://www.pykriging.com/

QuTiP
https://www.youtube.com/watch?v=aQw7FaRN7Zo&list=PLftRaVXG5xM7XZSZDEfYmGJwWwWCIrn97

Rock Physics Handbook distribution
	https://github.com/StanfordRockPhysics/The-Rock-Physics-Handbook-3rd-Edition

sklearn
	import sklearn
	print('The scikit-learn version is {}.'.format(sklearn.__version__))

tensorflow
	import tensorflow as tf
	print(tf.__version__)

time
	time.sleep(2)

TimeSeriesAnalysis
	https://github.com/equinor/TimeSeriesAnalysis

Welly
          https://github.com/agile-geoscience/welly

Getting a distro
git clone https://github.com/ingehap/geocomp-0118 geocomp-0118

https://statoilsrm.sharepoint.com/sites/NCS_Analytics/SitePages/Case-Examples.aspx
Øygarden model for ooze-rich claystone in Upper Oligocene (NO 34/8-A-33 H) 
BCs:
	1.7 < RHOB < 1.85 
Models:
	VP = 0.92 * VS + 1225.25 * [1 + 0.2*(RHOB – 1.8)]

Jan Ove inspired models  
BCs:
	VP(SB) = 1480 m/s   =>  DT(SB) = 205.9 us/ft  
	DTS(SB) = 1000 us/ft
Models:
	0.001 * DT * (RT * (TVDML + c))**(1/6) = a + b * VSHGR 
	0.01 * (RHOB + C*EXP(-D * TVDML))* DT**(1/4) = a + b * VSHGR 
	
https://jpt.spe.org/generating-shear-sonic-logs-by-machine-learning-lessons-learned-from-a-competition
https://statoilsrm.sharepoint.com/sites/NCS_Analytics/SitePages/Accessing-databases-using-python-and-Cx_Oracle.aspx
https://www.loop.equinor.com/en/stories/data-engineering.html
https://statoilsrm.sharepoint.com/sites/NCS_Analytics/SitePages/Case-Examples.aspx
https://statoilsrm.sharepoint.com/sites/NCS_Analytics/SitePages/Project-Management.aspx
https://www.loop.equinor.com/en/stories/ert.html
https://statoilsrm.sharepoint.com/sites/NCS_Analytics/SitePages/Don't-place-passwords-or.aspx
https://statoilsrm.sharepoint.com/sites/NCS_Analytics/SitePages/Error.aspx
https://statoilsrm.sharepoint.com/sites/NCS_Analytics/SitePages/Embedding-an-interactive-visualisation-onto-communication-site.aspx
https://statoilsrm.sharepoint.com/sites/ExplorationDigitalHome
https://statoilsrm.sharepoint.com/sites/NCS_Analytics/SitePages/Useful-Links.aspx
https://statoilsrm.sharepoint.com/sites/NCS_Analytics/SitePages/Working-with-GIT.aspx

https://statoilsrm.sharepoint.com/sites/NCS_Analytics/SitePages/Well-log-analytics.aspx?xsdata=MDN8MDF8fGJhYmE4ZDRmYTYyYjQzOTJhNjFmMThiY2YwN2M2OWEwfDNhYTRhMjM1YjZlMjQ4ZDU5MTk1N2ZjZjA1YjQ1OWIwfDF8MHw2Mzc2NzM3NzYzMTY2MTA4MDN8R29vZHxWR1ZoYlhOVFpXTjFjbWwwZVZObGNuWnBZMlY4ZXlKV0lqb2lNQzR3TGpBd01EQWlMQ0pRSWpvaUlpd2lRVTRpT2lJaUxDSlhWQ0k2TVRKOQ%3D%3D&sdata=WHcvcCtmKzBmdDBxbW5uSDBmVkc5ZUwrRjk4YWJpVHo5RXBsbjJBcm9rQT0%3D&ovuser=3aa4a235-b6e2-48d5-9195-7fcf05b459b0%2CTABH%40equinor.com

Books

Pawlowsky-Gahn, "Compositional Data Analysis"
https://read.amazon.ca/?asin=B005K047LS&language=en-CA

Web

http://www.compositionaldata.com/

History

1897, Karl Pearson
- "spurious correlation" for data that measures parts of some whole like proporsitions, percentage, ppm etc.
- If X, Y, and Z are uncorrelated, then X/Z and Y/Z are correlated.

1982, John Aitchison
- The log-ratio approach presented to the Royal Statistical Society 
- y(x) = {log(x1/xD), ..., log(xD-1/xD)} maps regular unit D-simplex S^D to R^D problem

2005, Aitchison and Egozcue
- Review article

Release Manager of the CGAL Project http://www.cgal.org/

Blogs
- https://www.pengesnakk.no/blog/

Buy online
- JetCarrier.Com

EU
https://ec.europa.eu/info/index_da

Fond
- https://www.morningstar.no/no/

Food
- https://www.hellofresh.no/pages/inspiration-delivered

House
- https://www.ikea.com/no/no/planner/smart-home/
- https://www.huseierne.no/

https://www.live-in-context.com/

Huseiernes
IAlt om bolig-seksjonen finner du artikler fra våre eksperter. Du finner også tips til hva du bør passe på for å vedlikeholde boligen din på best måte. Her har du alltid vedlikeholdskalenderen  lett tilgjengelig.

https://www.jetcarrier.com/

Membership
- https://www.coursera.org/
- SIAM; 31/12/2022
- SPE Member Number: 3243081; 31/12/2022
- APS Account Number: 61022141; 31/12/2022

Smarthus
- https://rackit.no/pages/smarthjem

Temperaturkontroll over hele boligen
- sentralstyring eller koblingsur
- temperaturen minimum 10-12 °C, da kan nemlig rørene fryse og sprekke
- innetemperatur på 18-21 grader i rom du oppholder deg i.

 Discover the transformer attention mechanism for neural machine translation:
 >> The Transformer Attention Mechanism
 Check out Basics of Linear Algebra for Machine Learning

Peter van ’t Riet
Luke, the Jew: An Introduction to the Jewish Character of the Gospel of Luke and the Acts of the Apostles; Paul, a Hellenistic Jew?
The Image of Man in the Torah.

Mark Ward in my book, Authorized: The Use and Misuse of the King James Bible.


Rock physics of sand-shale mixtures: Classifications, theoretical formulations and study on real dataset

B Khadem, MR Saberi, P Avseth - Marine and Petroleum Geology, 2021

Positive Zeta Potential in Sandstones Saturated with Natural Saline Brine

M Alarouj, H Collini, MD Jackson - Geophysical Research Letters

[13:13] Inger Ruth Wikander (Guest)
After what I remember, Statfjord has a good how to, further for Petro Elastic Model Norunn Skjei


4 Biblical language principles


1. Usage determines meaning.


2. Usage determines meaning—no, I mean it.

 Arika Okrent, In the Land of Invented Languages
God, Language, and Scripture by Moisés Silva, part of Foundations of Contemporary Interpretation.
Introductory, a modern classic: Exegetical Fallacies, by D. A. Carson.
More advanced, but short: Biblical Words and Their Meaning, by Moisés Silva.
Linguistics & Biblical Exegesis, part of the Lexham Methods Series, by Wendy Widder, Jeremy Thompson, and others.
More advanced, and long: The Hermeneutical Spiral, by Grant Osborne
Secular linguist John McWhorter, Words on the Move.

3. Look at every level of meaning, not just the word level


word, sentence, paragraph, section, book, testament, story of Scripture


4. Learn linguistic and literary labels.

poetry, history, and epistle
literary devices = personification, assonance, and zeugma
metaphors have a “target” and a “source”. 
Jonathan Pennington says precisely the same thing about this passage in his much-praised recent book, The Sermon on the Mount and Human Flourishing.

Sasha Bush
Gullfaks

https://www.udemy.com/

Alexander Kyurkchan Nadezhda Smirnova
Mathematical Modeling in Diffraction Theory

Erling Hugo Jensen, PhD, Bergen

https://www.esrf.fr/computing/scientific/exafs/gnxas.html

ModDEM
KITE model - uplift

Mormonism
https://youtu.be/d-xjSJKZbPQ

https://arxiver.moonhats.com/


Kevin Huo (creator of DataSciencePrep) here – for the last year, I’ve been writing a 301 page book, Ace the Data Science Interview which 

Hinsen, "Computation in Science"

Evaluation of different machine learning frameworks to predict CNL-FDC-PEF logs via hyperparameters optimization and feature selection

A Rostamian, E Heidaryan, M Ostadhassan - Journal of Petroleum Science and …, 2021

FLUID SATURATION METHODS FOR THE CONVENTIONAL CORE ANALYSIS STUDIES

A comparative study of permeability prediction for Eocene sandstones-Part 1: Application of modified Swanson models to MICP and NMR data
Z Zhang, A Weller - Geophysics, 2021

Sean D Devine, "Algorithmic Information Theory for Physicists and Natural Scientists"


https://read.amazon.ca/kindle-library

https://www.sciencedirect.com/science/article/abs/pii/S0920410521004174

https://iopscience.iop.org/book/978-0-7503-3607-9.pdf
https://iopscience.iop.org/book/978-0-7503-2747-3.pdf

Generation of Synthetic Sonic Slowness Logs from Real-Time Drilling Sensors Using Artificial Neural Network
A Abdulraheem - Journal of Energy Resources Technology, 2021

[PDF]Effect of Diagenesis on Geomechanical Properties of Organic‐rich Calcareous Shale: A Multiscale Investigation

TS Charlton, M Goodarzi, M Rouainia, AC Aplin… - Journal of Geophysical Research …

Machine Learning-A novel Approach of Well Logs Similarity based on Synchronization Measures to Predict Shear Sonic Logs


Wellsite Full Waveform Sonic Interpretation

JA Donald, E Wielemaker, C Holmes, T Neville - SPWLA 62nd Annual Logging …, 2021

A New Look at the Dual Depth of Investigation of LWD Propagation Resistivity Logging

GL Wang, D Homan, D Maggs, D Allen - SPWLA 62nd Annual Logging Symposium, 2021

Automatic Logging-While-Drilling Dipole Sonic Shear Processing Enabled by Physics-Driven Machine Learning

L Liang, T Lei, M Blyth - SPWLA 62nd Annual Logging Symposium, 2021

Rock physics templates for anisotropic and heterogeneous reservoir rocks considering mineralogy, texture and pore-filling fluid

OC Valdiviezo-Mijangos, LD Jaimes-Tejeda… - Journal of Natural Gas …, 2021

Diagnosing of clay distribution in argillaceous sandstone bArticley a rock physics template

J Nie, Z Qu, Y Cheng, X Wang, J Zhu, S Sun, L Zhao… - Geophysical Prospecting

[PDF]Determining reservoir intervals in the bowland shale using petrophysics and rock physics models
I Anderson, J Ma, X Wu, D Stow - Geophysical Journal International, 2021

A Born-WKBJ Pre-Stack Seismic Inversion Based on a 3-D Structural-Geology Model Building
 Article Aug 2021·IEEE Transactions on Geoscience and Remote Sensing  

Effective viscoelastic representation of gas-hydrate bearing sediments from finite-element...

Lectures on Stochastic Programming: Modeling and Theory, Third Edition. 2021
The above book is now available online from Society for Industrial and Applied Mathematics at: https://epubs.siam.org/doi/book/10.1137/1.9781611976595?ai=w9&ui=1m3⁡=H

Numerical Continuation and Bifurcation in Nonlinear PDEs. https://epubs.siam.org/doi/book/10.1137/1.9781611976618?ai=wa&ui=1m3⁡=H

On the Approximate Solutions of the Schrödinger Equation

N Khatiashvili - BOOK OF ABSTRACTS

Application of electrical rock typing for quantification of pore network geometry and cementation factor assessment

P Kolah-kaj, S Kord, A Soleymanzadeh - Journal of Petroleum Science and …, 2021

[PDF]Consistency and prior falsification of training data in seismic deep learning: Application to offshore deltaic reservoir characterization

A Pradhan, T Mukerji - arXiv preprint arXiv:2108.13670, 2021

[PDF]Rock physics model of shale: Predictive aspect

M Asaka, RM Holt, A Bakk - Journal of Geophysical Research: Solid Earth

Using Python Optional Arguments When Defining Functions
Splitting Datasets With scikit-learn and train_test_split()

[PDF]Rock physics model of shale: Predictive aspect

M Asaka, RM Holt, A Bakk - Journal of Geophysical Research: Solid Earth

[PDF]Effect of paleoclimate and paleoenvironment on organic matter accumulation in lacustrine shale: Constraints from lithofacies and element geochemistry in the northern …

H Hou, L Shao, Y Li, L Liu, G Liang, W Zhang, X Wang… - Journal of Petroleum …, 2021

Effects of microstructural and petrophysical properties on spontaneous imbibition in tight sandstone reservoirs

Y Xia, Z Tian, S Xu, W Wei, J Cai - Journal of Natural Gas Science and Engineering, 2021

[PDF]The stress-dependent elasticity in single rough fractures

J Ho, Y Ma, A Cheng, YE Li - First International Meeting for Applied Geoscience & …, 2021

Fast inversion of gravimetric profiles via a modified version of the Pereyra–Rosen algorithm

MZ Fernández-Muñiz, JLG Pallero, T Mukerji… - Journal of Earth System …, 2021

https://github.com/toddheitmann/PetroPy (Multimin)

[PDF]Bayesian inversion for rock composition and petrophysical endpoints in multimineral analysis

L Cheng, G Jin, RJ Michelena - First International Meeting for Applied Geoscience & …, 2021

Permeability prediction of multi-stage tight gas sandstones based on Bayesian regularization neural network

Y Zhou, X Zhao, C Jiang, S Liu, Z Han, G Wang - Marine and Petroleum Geology, 2021

Online Bible Dictionaries: Why Everyone Needs at Least One from the Logos Bible Software Blog

Rock Typing Based on Wetting-Phase Relative Permeability Data and Critical Pore Sizes
BA Yokeley, B Ghanbarian, M Sahimi - SPE Journal, 2021


Effect of water-based working fluid imbibition on static and dynamic compressive properties of anisotropic shale

Y Guo, X Li, L Huang, H Liu, Y Wu - Journal of Natural Gas Science and Engineering, 2021

Effects of Imbibition and Compaction during Well Shut-In on Ultimate Shale Oil Recovery: A Numerical Study

N Wijaya, J Sheng - SPE Reservoir Evaluation & Engineering, 2021

Effects of dolomitization on porosity–Permeability distribution in depositional sequences and its effects on reservoir quality, a case from Asmari Formation, SW Iran

A Omidpour, A Mahboubi, R Moussavi-Harami… - Journal of Petroleum …, 2021

A rock core wettability index using NMR T2 measurements

K Al-Garadi, A El-Husseiny, M Elsayed, P Connolly… - Journal of Petroleum …, 2021

[HTML]Improved well logs clustering algorithm for shale gas identification and formation evaluation

NP Szabó, BA Braun, MMG Abdelrahman, M Dobróka - Acta Geodaetica et …, 2021

Geostatistical Simulation of Facies and Petrophysical Properties for Heterogeneity Modeling in A Tidal Depositional Environment: A Case Study From Upper Shale …

WJ Al-Mudhafar - SPE/AAPG/SEG Unconventional Resources …, 2021

Petrophysical Characteristics of Silurian Mudstones from Central Taurides in Southern Turkey

Z Döner, Q Hu, M Kumral, MG Kibria, H Qiao, M Sun - Journal of Earth Science, 2021

---

Articles



[PDF]Structure-preserving Sparse Identification of Nonlinear Dynamics for Data-driven Modeling

K Lee, N Trask, P Stinis - arXiv preprint arXiv:2109.05364, 2021

[PDF]Randomized-gauge test for machine learning of Ising model order parameter

T Morishita, S Todo - arXiv preprint arXiv:2109.05533, 2021




---

Articles






Machine Learning for Multiple Petrophysical Properties Regression Based on Core Images and Well Logs in a Heterogenous Reservoir

T Lin, M Mezghani, C Xu, W Li - SPE Annual Technical Conference and Exhibition, 2021

Khuff and Pre-Khuff Reservoir Fracture Characterization using the Cross Dipole Shear Wave Imaging and Borehole Imaging Data Integration

P Menon, T Swedan, K Jan, MS Al-Shehhi… - SPE Annual Technical …, 2021

Relating Acoustic Anisotropy to Kerogen Content in Unconventional Formations-A Case Study in A Kerogen-Rich Unconventional Carbonate

Y Gordin, T Bradley, YO Rosenberg, A Canning… - SPE Annual Technical …, 2021

---

artikler



Hi Inge H. A.,

Robert  Klimentidis just uploaded "High-Resolution Imaging of Ordered Mixed-Layer Clays."

High-Resolution Imaging of Ordered Mixed-Layer Clays		 Robert  Klimentidis	
1986, Clays and Clay Minerals
View Paper ▸	 		Download PDF ⬇
 	
580 California St., Suite 400, San Francisco, CA, 94104

Unsubscribe   Privacy Policy   Terms of Service   

© 2021 Academia


Multi-scale pore characterization of Barakar shale in the Mand-Raigarh Basin, India: scientific upshots from geochemical approaches and imaging techniques

S Kumar, AK Varma, VA Mendhe, B Tiwari - Arabian Journal of Geosciences, 2021

https://github.com/thunil/Physics-Based-Deep-Learning
https://github.com/allegroai/clearml
https://github.com/guildai/guildai
https://github.com/hyperopt/hyperopt
https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms
https://github.com/optuna/optuna
https://github.com/zotero/zotero
https://towardsdatascience.com/hyperparameter-tuning-a-practical-guide-and-template-b3bf0504f095
https://dvc.org/
https://my.guild.ai/
https://www.scopus.com/home.uri
https://gitlab.cern.ch/idinu/dl1-hyperparameter-optimisation
https://icite.od.nih.gov/
https://www.kdnuggets.com/2021/01/top-10-computer-vision-papers-2020.html
https://carpentries-incubator.github.io/jekyll-pages-novice/
https://www.mygreatlearning.com/blog/ai-researchers-and-leaders?utm_source=email&utm_medium=email&utm_campaign=aiml_blog_14may
https://dataawesome.substack.com/archive?sort=new
https://xavierbourretsicotte.github.io/
https://catalins.tech/how-to-contribute-to-open-source-projects-as-a-beginner
https://agilescientific.com/blog/tag/petrophysics
https://erlend-viggen.no/dlis-files/
https://levelup.gitconnected.com/25-github-repositories-every-python-developer-should-know-ac848f6aa1fe

number = float('Inf')
import this

www.nmrpetrophysics.com
https://petrowiki.spe.org/Drilling_fluid_types
Emerson - Watch Recording


pip install virtualenv

Sergey Tsimfer og Alexey Kozehvin ved Gazprom-Neft har en del åpne prosjekter i ML rettet mot 
 olje og gass på  https://medium.com/data-analysis-center

https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Geology
https://agilescientific.com/blog/2019/3/21/x-lines-of-python-ternary-diagrams

https://wiki.seg.org/wiki/Seismic_petrophysics:_Part_2

https://www.sciencedirect.com/science/article/abs/pii/S1365160921001787
https://onepetro.org/SPWLAALS/proceedings/SPWLA21/3-SPWLA21/D031S024R001/463020
https://www.freepatentsonline.com/y2021/0033746.html
https://shiguerunagata.com/ms_ml/
https://www.mdpi.com/2077-1312/9/6/666/htm
https://mycarta.wordpress.com/2020/09/19/geoscience-machine-learning-bits-and-bobs-data-completeness/

https://www.nvidia.com/en-us/training/
https://pythonprogramming.net/matplotlib-3d-scatterplot-tutorial/


https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?tabs=python
https://www.sciencedirect.com/science/article/abs/pii/S0920410518310246

https://deepai.org/
https://www.linuxvmimages.com/images/

https://archive.org/details/@mirtitles
https://exlean.org/
https://mirtitles.org/
https://pair.withgoogle.com/guidebook

https://stackabuse.com/tag/python


https://eng.uber.com/orbit/
https://leanprover-community.github.io/
https://blog.tensorflow.org/

http://www.cs.man.ac.uk/~gbrown/stability/
https://eng.uber.com/optimal-feature-discovery-ml



https://coderefinery.github.io/social-coding/software_citation/


Software citation¶

- Get a DOI using Zenodo.
- Make it easy for scripts and tools, use the Citation file format:

Publishing papers about software¶

- The Journal of Open Source Software
- In which journals should I publish my software?
- https://www.force11.org/software-citation-principles

FAIR principles¶

https://softdev4research.github.io/4OSS-lesson/.
- http://depth-first.com/articles/2006/12/29/dispelling-open-source-confusion-an-introduction-to-licenses/
- http://oss-watch.ac.uk/resources/ipr
- http://rkd.zgib.net/scicomp/open-science/open-science.html
- https://choosealicense.com (can send automatic pull request to your GitHub repo)
- https://hintjens.gitbooks.io/social-architecture/content/chapter2.html
- https://softdev4research.github.io/4OSS-lesson/
- https://softdev4research.github.io/recommendations/
- https://tldrlegal.com/
- https://users.aalto.fi/~darstr1/cheatsheets/ipr-cheatsheet.pdf
- https://www.software.ac.uk/choosing-open-source-licence
- http://www.oreilly.com/openbook/osfreesoft/
- http://www.rosenlaw.com/oslbook.htm
- http://lib.tkk.fi/Diss/2005/isbn9529187793/isbn9529187793.pdf
- https://www.software.ac.uk/resources/guides/adopting-open-source-licence
- https://jacobian.org/2009/sep/17/contributor-license-agreements/
- https://github.com/DEGoodmanWilson/Ethical-Resources
- https://opensource.google/docs/patching/#forbidden
- https://opensource.google/docs/
- https://opensource.guide/


Intentional learner:
1. Set small, clear goals
2. Remove distractions
3. Actively seek actionable feedback
4. Practice in areas you want to grow in
5. Practice regular reflection - evaluate yourself, determine your learning needs

1 What is the field?
2 What is the research question?
Read and assess a lot of papers: Trends? Open areas? Systematic review?
	In the first pass
		scan the abstract: problem statement, methods, and results.
	In the second 
		highlight the relevant sections, take notes for each paper.
	In the third pass
		synthesize the concepts across papers. Methods to measure  novelty, diversity, serendipity. 
		consolidate them into a single note and compare their pros and cons. Gaps ?
Contact a research community where people work on a similar topic.
Test a methodology on several topics or explore a topic with several methods?
Literature search for distinctiveness
	1. Google Scholar, PubMed, Scopus, etc. + keywords
	2. Scan the reference lists of relevant articles.
	3. set up automated alerts: TOC alerts, citation alerts, and keyword alerts.
	4. Keeping a tab on the publications in your field.
           5. This course: How to conduct a literature search and review
Search for general solutions that can be applied to other problems.
how large is the potential upside
Prof. Bwisa’s explains the basics of how to write the statement of the problem.
course: How to write a statement of the problem
dependency graph of ideas

3 Hypothesis
Background study:
	Assess the credibility of the literature: Search for papers on journals’ site to check for any corrections or retractions.
	Read the cited literature
	Organize literature wrt theme, IMRAD section or chronology.
Use of tools for literature search and reference management.
        Mendeley          
        Add CiteULike/Zotero libs to Mendeley File Organizer (Tools > Options > File Organizer).

4 Methods
experiment = method + RQ/problem + dataset

5 Meta method:
I create a file entry for each day:
     what I’m doing, ideas I have, and experimental results (pasting in plots and tables).
Every 2 weeks, I do a second file by condenseing the information into a summary:
experimental findings, insights, code progress (what did I implement), and next steps / future work. 
look at the previous week to see if I followed up on everything I thought of that week. 
Transfer good ideas that is outside timeframe into a third file
Monitoring use of time.
spend one day per week on something totally different, epsilon-greedy exploration, 
regularly setting aside time for improving your general knowledge of ML: textbooks, theses and paper
spending a lot of time reimplementing ideas from papers
Numerical Optimization by Nocedal & Wright,
Elements of Information Theory by Cover & Thomas.
Results:
Interpretation:
Discuss possible implications:





 
write about what I’ve learnt and publish it online. 

IMRaD (Introduction, Methods, Results, and Discussion) structure
- Introduction, state the research problem, significance
- Materials/Methods what you did and how you conducted your research – the tools, techniques, and instruments used, the data collection methods, and details about the lab environment. Ensuring clarity in this section is critical for success.
- The results section must include complete details of the most significant findings in your study and indicate whether you were able to solve the problem outlined in the introduction. Using tables and figures will help to simplify complex data and results for readers.
- The discussion section is where you evaluate your results in the context of existing published literature, analyze the implications and meaning of your findings, draw conclusions, and discuss the impact of your research.

abstract 
- the main premise of your research and the questions you seek to answer. 
the specific guidelines of the journal you are submitting to.

Incorrect usage of words, grammar and spelling errors, and flaws in sentence construction are certain to lead to rejection. 
coherent transition between sections?
Double-check the data and figures and read the manuscript out loud

You could request colleagues or fellow researchers to go through your manuscript before submission but, if they are not experts in the same field, they may miss out on errors. In such cases, you may want to consider using professional editing services to help you improve sentence structure, grammar, word choice, style, logic and flow to create a polished manuscript that has a 24% greater chance of journal acceptance4.

Once you have prepared your manuscript as per your target journal, we recommend doing a comprehensive set of submission readiness checks to ensure your paper is structurally sound, complete with all the relevant sections, and is devoid of language errors. Most importantly, you need to check for any accidental or unintentional plagiarism – i.e., not correctly citing, paraphrasing or quoting another’s work – which is considered a copyright infringement by the journal, can not only lead to rejection, but also stir up trouble for you and cause irreversible damage to your reputation and career. Also make sure you have all the ethical declarations in place, such as conflicts of interest and compliance approvals for studies involving human or animal participants.

As a last step, before submitting your manuscript to your target journal, review the document carefully and check the following points:

- Is your research paper complete, optimized and submission ready?
- Have all authors agreed the content of the submitted manuscript?
- Is your paper aligned with your target journals publication policies?
- Have you created a winning submission package, with all the necessary details?
- Does it include a persuasive cover letter that showcases your research?
follow our simple manuscript writing guide, you will have the base to create a winning manuscript, with a great chance at acceptance. If you face any hurdles or need support along the way, be sure to explore R Upskill’s bite-sized learning modules on research writing, designed by researchers, for researchers. And once you have mastered the tips for writing a research paper, and crafting a great submission package, use R Pubsure’s comprehensive AI-assisted manuscript evaluation to avoid errors that lead to desk rejection and optimize your paper for submission to your target journal.

databases such as GoPubMed

Simple strategies that will help you simplify your literature search
	Reference manager = Mendley
- Identify main keywords: synonyms and/or alternative phrases for each keyword
- Tap multiple channels
- Search by citations: conduct a backward search. 
- Bookmark your searches: (Ctrl+D)
- Subscribe to publisher newsletters
- Recommended – Find one home for all your research
- multiple platforms like Mendeley, Zotero and Orcid
- Convenient search filters and an instant feedback features
- tracking reading history and patterns, and bookmarking papers with one click


#3 — BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

In this paper, the team at Google Research put forward the natural language processing (NLP) model that represented a step-function increase in our capabilities in for text analysis.

Though there’s some controversy over exactly why BERT works so well, this is a great reminder that the machine learning field may have uncovered successful approaches without fully understanding how they work. As with nature, artificial neural networks are steeped in mystery.

How to use:

- The BERT paper is imminently readable and contains some suggested default hyperparameter settings as a valuable starting point (see Appendix A.3).
- Whether or not you’re new to NLP, check out Jay Alammar’s “A Visual Guide to Using BERT for the First Time” for a charming illustration of BERT’s capabilities.
- Also, check out ktrain, a package that sits atop Keras (which in turn sits atop TensorFlow) that allows you to effortlessly implement BERT in your work. Arun Maiya developed this powerful library to enable speed to insight for NLP, image recognition, and graph-based approaches.

#4 — The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks

While NLP models are getting larger (see GPT-3’s 175 billion parameters), there’s been an orthogonal effort to find smaller, faster, more efficient neural networks. These networks promise quicker runtimes, lower training costs, and less demand for compute resources.

In this groundbreaking paper, machine learning wiz kids Jonathan Frankle and Michael Carbin outline a pruning approach to uncover sparse sub-networks that can attain comparable performance to the original, significantly larger neural network.


via Nolan Day’s “Breaking down the Lottery Ticket Hypothesis.”

The Lottery Ticket refers to the connections with initial weights that make them particularly effective. The finding offers many advantages in storage, runtime, and computational performance - and won abest paper award at ICLR 2019. Further research has built on this technique, proving its applicability and applying it to an originally sparse network.

How to use:

- Consider pruning your neural nets before putting them into production. Pruning network weights can reduce the number of parameters by 90%+ while still achieving the same level of performance as the original network.
- Also, check out this episode of the Data Exchange podcast where Ben Lorica talks to Neural Magic, a startup that’s looking to capitalize on techniques such as pruning and quantization with a slick UI that makes achieving sparsity easier.
Read more:

- Check out this interesting sidebar from one of the “The Lottery Ticket” authors about flaws in how the machine learning community evaluates good ideas.

• Use minimalism to achieve clarity. While you are writing, ask yourself: is it possible to preserve my original message without that punctuation mark, that word, that sentence, that paragraph or that section? Remove extra words or commas whenever you can. 

• Decide on your paper’s theme and two or three points you want every reader to remember. This theme and these points form the single thread that runs through your piece. The words, sentences, paragraphs and sections are the needlework that holds it together. If something isn’t needed to help the reader to understand the main theme, omit it.

• Limit each paragraph to a single message. A single sentence can be a paragraph. Each paragraph should explore that message by first asking a question and then progressing to an idea, and sometimes to an answer. It’s also perfectly fine to raise questions in a paragraph and leave them unanswered. 

• Keep sentences short, simply constructed and direct. Concise, clear sentences work well for scientific explanations. Minimize clauses, compound sentences and transition words — such as ‘however’ or ‘thus’ — so that the reader can focus on the main message. 

• Don’t slow the reader down. Avoid footnotes because they break the flow of thoughts and send your eyes darting back and forth while your hands are turning pages or clicking on links. Try to avoid jargon, buzzwords or overly technical language. And don’t use the same word repeatedly — it’s boring.

• Don’t over-elaborate. Only use an adjective if it’s relevant. Your paper is not a dialogue with the readers’ potential questions, so don’t go overboard anticipating them. Don’t say the same thing in three different ways in any single section. Don’t say both ‘elucidate’ and ‘elaborate’. Just choose one, or you risk that your readers will give up.

• And don’t worry too much about readers who want to find a way to argue about every tangential point and list all possible qualifications for every statement. Just enjoy writing.

	Related

Nature collection: Mentoring
• With regard to grammar, spoken language and common sense are generally better guides for a first draft than rule books. It’s more important to be understood than it is to form a grammatically perfect sentence.

• Dashes should emphasize the clauses you consider most important — without using bold or italics — and not only for defining terms. (Parentheses can present clauses more quietly and gently than commas.) Don’t lean on semicolons as a crutch to join loosely linked ideas. This only encourages bad writing. You can occasionally use contractions such as isn’t, don’t, it’s and shouldn’t. Don’t be overly formal. And don’t use exclamation marks to call attention to the significance of a point. You could say ‘surprisingly’ or ‘intriguingly’ instead, but don’t overdo it. Use these words only once or twice per paper. 

• Inject questions and less-formal language to break up tone and maintain a friendly feeling. Colloquial expressions can be good for this, but they shouldn’t be too narrowly tied to a region. Similarly, use a personal tone because it can help to engage a reader. Impersonal, passive text doesn’t fool anyone into thinking you’re being objective: “Earth is the centre of this Solar System” isn’t any more objective or factual than “We are at the centre of our Solar System.”

• Choose concrete language and examples. If you must talk about arbitrary colours of an abstract sphere, it’s more gripping to speak of this sphere as a red balloon or a blue billiard ball. 

• Avoid placing equations in the middle of sentences. Mathematics is not the same as English, and we shouldn’t pretend it is. To separate equations from text, you can use line breaks, white space, supplementary sections, intuitive notation and clear explanations of how to translate from assumptions to equations and back to results.

• When you think you’re done, read your work aloud to yourself or a friend. Find a good editor you can trust and who will spend real time and thought on your work. Try to make life as easy as possible for your editing friends. Number pages and double space. 

Nature574, 441-442 (2019)

Hart G. 2014. Writing for Science Journals: tips, tricks, and a learning plan
https://github.com/henrikmidtiby/todonotes
https://github.com/alan-turing-institute/the-turing-way
https://best-practice-and-impact.github.io/qa-of-code-guidance/intro.html
https://github.com/CitSci-WG/guide
https://github.com/alan-turing-institute/TuringDataStories
https://fairplus.github.io/the-fair-cookbook/content/home.html
https://stackabuse.com/

---

10 Tips for Research and a PhD



1) Read broadly.

Instead, I use services such as arXiv sanity preserver, arXiv
click here to know more about R Discovery, or download the free app from Google Play or the App Store.ist, my Twitter feed, and recommendations from friends to stay up-to-date and to seek out different topics. 

I also generally prefer to read 10 papers superficially rather than one paper in-depth (as suggested by Jeff Dean). With a search-able paper management system (I use Mendeley) 

2) Work on two things


3) Be ambitious.


4) Collaborate.


5) Be proactive.

This is probably the most important piece of advice. Don't restrict yourself to the people in your immediate circle.

Reach out to people. The main value of conferences is in bringing people together. Before a conference, look up who is going (by checking authors of accepted papers) and email them. Try to be respectful, briefly introduce yourself, and state why you'd like to meet them (a useful mnemonic is Inigo Montoya's Guide to Networking Success). Most senior people make time for such meetings. Try to talk to many people and particularly seek out those who are not already well-known.

Outside of conferences, it is often useful to ask people who have worked in your area for research advice via email. It's amazing to see how many people in our field are genuinely helpful. Proper email etiquette is important, however and makes it more likely that a busy researcher will respond. In particular, you should make it clear that you've done your research and explored alternative solutions before contacting them.

Beyond advice, such connections may lead to other opportunities further down the line: job offers, collaborations, mentorship, and even friendship. Many of my collaborations started through such connections—meetings at a conference, a cold email, a Twitter message. The important thing is that they are based on mutual interests and respect. So be conscious of other's people time. In addition, early career researchers with shared interests will often be much more open to collaborations than senior researchers who already have many commitments.

6) Write a blog.

Another great way to start blogging is to discuss what you have just become knowledgeable about. Rachel Thomas puts this as "you are best positioned to help people one step behind you". If you have just delved into a specialised area, why not save others the time and summarise the work and your insights. Most of my blog posts—from gradient descent to word embeddings—started this way. If you have just learned how to do something cool, tell others about it. Conversely, if you want to learn about a certain topic but cannot find information about it online, consider creating that resource yourself. Starting your own blog has never been easier.

References and inspiration

Finally, here are a few more pieces that served as inspiration:

- Andrey Karpathy's A Survival Guide to a PhD
- The Frontiers in Natural Language Processing Expert Responses at the Deep Learning Indaba 2018
- John Schulman's An Opinionated Guide to ML Research
- Andrey Kurenkov's Lessons Learned the Hard Way in Grad School (so far)
- Volkan Cirik's PhD 101
- Tim Dettmer's How to Pick Your Grad School
- Isabelle Augenstein's Increasing Well-Being in Academia
- Richard Hamming's You and Your Research
- Fei-Fei Li's De-Mystifying Good Research and Good Papers
- Sam Altman's How To Be Successful and associated Twitter thread
- Stuart K. Card's The PhD Thesis Deconstructed
- Tweets from Himan Abdollahpouri, Chip Huyen, and many others


A research paper presents the research problem, study method, findings, and the significance

Introduction
what the paper is about and what is the significance of the study. 
the research gap leading to the research problem will give a context and narrative. Once you explain the research problem, you should also mention how resolving it would provide significant insights. Any specific objectives and the theoretical framework should also be mentioned. One thing to consider while writing this section is that the information should be generic but should help the readers along to the more specific details that will follow in the Methods section.&nbsp;

Materials and Methods
How did you arrive at the results?
Are there enough details to reproduce the results?
sources of material, equipment, models, and data collection methods. 
controls used or lab conditions
justify the experimental design
diagrams or images explaining the experimental setup

To make this section effective refrain from adding extraneous details. Another common mistake that researchers make is to include the results, which should be avoided.&nbsp;

Bonus tip: Most authors find writing this section&nbsp;easy, and you can begin writing your manuscript with the Methods section.

Results

Using tables and figures is one of the most common ways of presenting the results in a succinct manner. If you think some results would be particularly interesting to the readers, you can highlight them.&nbsp;

An important aspect researchers should keep in mind is avoiding duplication of data, which means data that is presented in tables and figures should not be reiterated in text. Equally important is to steer away from adding any information here that would take away the focus from the results. Another common pitfall is discussing the findings, which should be reserved for the Discussion section.&nbsp;

Bonus tip: Keep the section focused on presenting your results. This part of the paper is usually brief, so don’t use it to discuss or analyze any of the findings.

Discussion

answering the question “So what?” as you would interpret your results. 
 tie in with the Introduction section, but from specific it should move to a broader spectrum

Your aim should be to explain how the results help fix the gap in existing knowledge. Depending on your research, you can discuss whether the results were expected and draw comparisons with the previous work on the research topic. One important point to remember is to mention any limitations of your study.&nbsp;

Some common errors you should avoid are restating the results without interpreting them. Another mistake many researchers make is discussing results that are not part of the Results section. Keep your writing focused on the set of results that are crucial to establish the significance of your work.&nbsp;

Bonus tip: The Conclusion section can be part of the Discussion section or an independent section depending on the specifications of the journal you are submitting to. This section should provide the key message you wish to convey through your work, such as&nbsp;any further research that needs to be undertaken, and draw any final conclusions that are generic.



	Online search onGoogle Scholar(free),Scopus(paid), or Web of Science(paid). 

	Google Scholar alerts- Set up alerts with your keywords or “follow” the professors whose work you are interested in.

	Table of contents- Setup alerts to receive the table of contents of the journals where articles from your area are frequently published.JournalTOCsis a great service as it combines and sends alerts for most journals. People have varying views regarding the importance of looking through the table of contents. However, I have found it useful to get over the feeling of having blinders on — it gives a peek into the developments in the broader scientific world.
	

https://neptune.ai/blog/jupyterlab-extensions-for-machine-learning
https://docs.neptune.ai/
https://github.com/jupyterlab/jupyterlab-google-drive
https://github.com/jupyterlab/jupyterlab-github

https://medium.com/staqu-dev-logs/keeping-python-code-clean-with-pre-commit-hooks-black-flake8-and-isort-cac8b01e0ea1

https://stackoverflow.com/questions/57467943/how-to-make-3d-4-variable-ternary-pyramid-plot-in-r-or-python

Neptune notebook extension
https://app.neptune.ai/ingehap/-/projects

Abhayparashar31/feature-engineering
https://github.com/Abhayparashar31/feature-engineering

https://www.youtube.com/playlist?list=PLpX1jXuNTXGovM-j2JZBYGTA7snDFo9Gw



ColabFit
https://colabfit.openkim.org/

https://github.com/thunil/Physics-Based-Deep-Learning

FermiNet
https://github.com/deepmind/ferminet

HEPML-LivingReview
https://iml-wg.github.io/HEPML-LivingReview/

Diamond
https://github.com/bbuchfink/diamond

https://github.com/jcrozum/PyStableMotifs

RoseTTAFold
https://pythonrepo.com/repo/RosettaCommons-RoseTTAFold-python-deep-learning

Scrivener 3 for Windows
90F5067D-99859467-91DC406E-3376539B-41EDA015

Agile
https://github.com/agile-geoscience
https://agilescientific.com/blog

AI & Machine Learning in Geophysics
https://www.youtube.com/watch?v=i1Mqq0ozh_4

Petrophysics
https://www.linkedin.com/pulse/machine-learning-approach-petrophysical-using-random-forest/

Peter bolgebrygg
https://github.com/bolgebrygg?tab=repositories

Lyon, Reassessing Selah

https://github.com/tgvaughan/sicm


References

- Copeland, J. (2015). Computability. Turing, Gödel, Church and Beyond. The MIT Press.
- Dawson, J.W. (1984). Kurt Gödel in Sharper Focus.
- Dawson, J.W. (1998). Kurt Gödel and the Limits of Logic.
- Dawson, J.W. (2006). Logical Dilemmas: The Life and Work of Kurt Gödel. CRC Press. Boca Raton, Florida.
- Goldstein, R.N. (2005). Incompleteness: The Proof and Paradox of Kurt Gödel. W.W. Norton & Company.
- Graham, E. (2018). “Adventures in Fine Hall” in Princeton Alumni Weekly
- Holt, J. (2018). When Einstein Walked with Gödel. Farrar, Straus and Giroux.
- Menger, K. (1981). Recollections of Kurt Godel.
- Taussky-Todd, O. (1987). Gödel Remembered. Bibliopolis, Naples, Italy.
- Taussky-Todd, O. (1988). Remembrances of Kurt Gödel. http://vigeland.caltech.edu/ist4/lectures/Todd%20on%20Godel.pdf
- Sigmund, K. (2017). Exact Thinking in Demented Times*. Basic Books. New York.

Coles, "An Introduction to Statistical Modeling of Extreme Values"


Helen Scales
The Brilliant Abyss: True Tales of Exploring the Deep Sea, Discovering Hidden Life and Selling the Seabed

Chacon, "Pro Git"
https://git-scm.com/book/en/v2

Git Workflow
http://documentup.com/skwp/git-workflows-book#

Shaw, "CPython Internals: Your Guide to the Python 3 Interpreter"



https://mrava87.github.io/

Mohaghegh, "Shale Analytics: Data-Driven ..."
Carrajal, "Intelligent Digital Oil --"
Ahmed, "Equations of State and PVT Analysis"

https://www.sciencedirect.com/science/article/abs/pii/S0309170820301366

Here is a link to see the full repository:https://github.com/awesomeahi95/Hotel_Review_NLP

Use markdowns
Keep all your imports at the top
Use visualisations with Seaborn poster content 
: Visualisations is a must in data science reporting — what better way to communicate your findings. But we can improve these visualisations with seaborn’s context ‘poster’, this makes the visualisation more bold and with clearer text. This makes matplotlib visualisations look better as well.


Code used for better visualisation

Make it digestable and easy to navigate: Using subtitle markdowns with numbers like 1.4.2 makes it easier to follow the steps taken in the notebook. For a given notebook you maybe performing certain tasks to your data, if there is a sequence of cells achieving one task, putting that under a numbered subtitle can help to both navigate up and down the notebook and to understand exactly what the next few cells are dedicated to achieving.


Example for digestable code

Use multiple notebooks for one report: This may not be possible for all projects as some companies may have certain rules with coding practices and only choose to use one notebook but otherwise, this can be very useful. When structuring a data science project, there are usually clear stages, such as EDA and modelling. For all these stages you can dedicate each stage a notebook. Not only does this make it more digestable, but someone else can run one notebook for a specific stage instead of running a single long notebook.

I’d also recommend saving each dataframe/dataset or model created in a notebook at the end, and saving them in folder for data or models in your repo, then import them back in the notebook used for the next stage. This helps with going back to older versions of manipulated data and models.


List of notebooks used for project
Create python scripts for functions and classes:
 Notebooks more goal driven by keeping it more about the steps taken and why, as those parts are what you would want to see when taking a quick look.
 Keep the functions and classes saved in scripts which can be imported into your notebook for use.
 Make sure your python scripts are well written and have detailed documentation.


Class with documentation

README


In terms of simplifying and summarising everything that is going on inside you project repository, READMEs are the perfect way of achieving this. As soon as a person opens your repository, under the files the first thing you can see is your README markdown. This is great for potential employers to look at, your non-technical colleagues, and your technical colleagues. This is where you aim to explain what you intentions were for the project, and you can include the context for why this project is being done. You can detail the structure of your files, the steps taken, and add some visualisations.

State your business case: Before going on about what you have done, giving some context would be highly beneficial to anyone reading. This part makes the results look more impressive as you can tell in a story “what had been” and then the project should show “what can be done” and “how”.


Business case

Table of contents with navigation links: A contents table can go a long way, especially if your README had a lot of information in it. Giving the reader a summary of what they can read in the README and the ability to jump to specific parts is a major convenience.


Example for table of contents

File descriptions with navigation links: Adding a small description for each file can also greatly help the reader understand what each component of the repository does or contains. Again, add links to simplify navigation.


Example of file descriptions

Use drop downs: Markdowns have the ability to use drop downs, and this can help shrink the length of your README when someone wants to go through it. You can choose to have some sections already hidden and with option to show the section and vice versa.


Examples for both states of drop down

Executive summary: This is the bulk of the README where you can go over the steps of your project with concise descriptions for what you did and what you found out at each stage, accompanied with visualisations (in image format). Make sure the descriptions don’t go too technical as the README is the perfect place for non-technical people to see your project, and you don’t want them to read about the specifics of code used in a function.


The beginning of executive summary

Future improvements: After the results, end with a part dedicated to future work/improvements to do with this project, and/or what else you may plan to do in the future in regard to the topic of the project or data science.


Example of a good way to end a README

Aristoteles inndeling av påstander 
	apodiktisk – bevisbar, nødvendigvis korrekt 
	dialektisk – sannsynliggjøre (avklare et problem, avgrense et begrep)  

1. Abstract: One paragraph synthesis of the entire document.
2. Introduction: Field, problems, and contributions.
3. Related work: To-date solutions and how they are lacking
4. Body: Free-zone. Describe your innovative work here.
5. Results: Comparison to the state-of-the-art; proof of usefulness
6. Conclusions: Sum-up and avenues for future investigation.

your text should be a constant stream of arguments and conclusions. 

#4: A Strong Related Work is a Strong Work

related work is two-fold: to remark the important literature and to delineate a common issue with most to-date solutions.

Why should there be another paper if there is no lingering problem to be solved?

A researcher’s eye sees the gap in the literature.

The paragraph begins enumerating the seminal one-stage detection architectures. Then, in yellow, it states the “gap”: one-stage detectors are faster but less accurate than two-stage approaches. In contrast, their work investigates: is it possible to be as accurate while retaining the speed?. Finally, they emphasize that their approach is based on a novel loss, not an innovative architecture. In sum, we have been presented the methods, their common issue, and how the authors addressed it. We now know exactly why this paper exists: to show it is possible to have high accuracy one stage detectors.

On a side note, the microstructure of these paragraphs is outstanding. It constantly poses arguments and ties them together. The first paragraph even has a mid-paragraph resolution. There is no limit to how micro you can get.

#5: The Reordering Game


For each paragraph, consider all of its sentences independently. Can you reorder them without compromising the overall meaning? If almost no scrambling is possible, you have a clear and growing argument. Else, you might be just throwing one argument after another, until the last sentence comes to round up everything. Sentence and paragraph order matters; some orders are more effective at delivering a message than others.

On the Focal Loss example, if we move the first highlighted sentence down to just before the second, the message is more or less retained. However, this created a long stream of facts about detectors. Putting that sentence in the middle gives the readers a pause to breathe and to understand why these facts were given, easing the digestion of the next set of facts.

This article itself is reorderable: it is made of ten individual tips that can be said in any order. However, some orders place similar ideas closer and distinct ideas apart, improving the overall presentation. In many cases, much can be improved by just ordering ideas properly. Order towards a climax.

#6: Do Not Repeat Yourself


you should have at least one table that sums up the data on most of the plots. 

The Naked Podcast
https://nakedbiblepodcast.com/episodes/

Concrete
- Gplearn

https://researchsoftwarehour.github.io
https://www.getzola.org/

The September TLE Digital Edition features a special section on rock physics. Read now with subscription.

http://128.97.46.212/videos/

Kim Arild Hammerstads bok om politiske skandaler i Norge.

There are few titles already on the Internet Archive which I not posted on the blog so far. You can check them at  https://archive.org/details/@mirtitles

In this post, we will see the book Thermodynamics, Statistical Physics, and Kinetics by Yu. B. Rumer and M. Sh. Ryvkin
You can get the book here.
Follow us on The Internet Archive: https://archive.org/details/@mirtitles
Fork us at GitLab: https://gitlab.com/mirtitles/
Add new entries to the detailed book catalog here.

 Pythonic Programming: Tips for Becoming an Idiomatic Python Programmer 
Dmitry Zinoviev



---

___


out-of-Africa hypothesis
H. sapiens (‘wise man’) appears to have emerged in Africa about 150 thousand years ago

Red Queen hypothesis 
predators and prey are engaged in a constant battle, with predators evolving better predation strategies and techniques and prey doing likewise.

The Ordovician period was terminated abruptly 440 million years ago, the Devonian 350 million years ago, the Permian period 250 million years ago, the Triassic 205 million years ago, and the Cretaceous 65 million years ago.



- Inheritance is encoded in DNA

Noticing that blood washed through all organs of the body, Aristotle ascribed inheritance to the blood, a view that lingers even now as a metaphor. He considered semen to be purified blood which, on copulation, mingled with menstrual blood and brought forth the next generation.

- Energy is conserved

The Greeks actually called it ὲνὲργεια, which translates literally into ‘in work’,

Aristotle (384–322 BCE) speculated that an arrow was kept in flight by the action of vortices in the air behind it and concluded, therefore, that an arrow must quickly come to rest in a vacuum.

As far as energy stored in matter is concerned, it is entirely composed of kinetic and potential energy.
The exception to the universality of the terms kinetic and potential energy is the energy of electromagnetic radiation (for instance, the energy of light,
two forms of energy—kinetic energy (the capacity to do work by virtue of motion) and potential energy (the capacity to do work by virtue of position).

All viable engines have a cold sink is one statement of the Second Law of thermodynamics.

In 1995, Ted Jacobson9 showed that if we combine the Clausius expression for the change of entropy when heat enters a region with an assertion about the relation of entropy to the area of the surface bounding the region (in fact, the two are proportional, as they are known to be for the surface surrounding a black hole), then the local structure of spacetime is distorted in exactly the way predicted by Einstein’s equations for general relativity. In other words, in a rather refined mathematical sense, the Second Law implies the existence of Einstein’s equations of general relativity!

Matter is atomic

https://brightmorningstar.org/

No more than two electrons can occupy any one orbital, and if two electrons are present in the same orbital, then their spins must be paired.

The vertical columns are called groups and the horizontal rows are called periods.

metals appear on the left of a period and the non-metals appear on the right. The elements in the long thin central section, such as iron (Fe) and platinum (Pt), are the transition metals, as they represent a transition between the very reactive metals, such as sodium (Na) and calcium (Ca), on the left of the table and the much less reactive metals, such as tin (Sn) and lead (Pb), on the right. The very thin twenty-eight element section placed underneath the table consists of the inner transition metals.

The inner transition metals are all very similar in chemical properties and were among the most recent elements to be separated and identified. In fact, the very bottom line, following uranium (U), consists only of elements that have been made artificially.

With two simple ideas—that electrons organize themselves so as to achieve the lowest possible energy, and that no more than two electrons can occupy any given orbital—the pattern of matter becomes understandable. Chemistry is at the heart of understanding matter, and at the very heart of chemistry lies its currency of discourse, atoms.

Symmetry limits, guides, and drives

Noether’s theorem
When there is a symmetry, there is always a corresponding conservation law.

Pauli found that he could account for certain details of the radiation emitted by atoms only if the wavefunction for the atom changed sign when any two electrons were interchanged. We say that the wavefunction must be antisymmetric (that is, change sign) under electron interchange. The Pauli exclusion principle, that no more than two electrons can occupy any atomic orbital, follows from this deeper requirement,



---

___


https://investor.dn.no/#!/Kurser/Fond/
https://coinmarketcap.com/
https://www.statista.com/
https://www.nordnet.no/market/stocks

by Johannes Lederer, Fundamentals of High-Dimensional Statistics:...

Kinematic self-replication in reconfigurable organisms
Sam Kriegman, Douglas Blackiston, Michael Levin and Josh Bongard
PNAS. 2021; 118:e2112672118. 
http://www.pnas.org/content/118/49/e2112672118

Transformational machine learning: Learning how to learn from many related scientific problems
Ivan Olier, Oghenejokpeme I. Orhobor, Tirtharaj Dash, Andy M. Davis, Larisa N. Soldatova, Joaquin Vanschoren and Ross D. King
PNAS. 2021; 118:e2108013118. 
http://www.pnas.org/content/118/49/e2108013118

Distributional conformal prediction
Victor Chernozhukov, Kaspar Wüthrich and Yinchu Zhu
PNAS. 2021; 118:e2107794118. 
http://www.pnas.org/content/118/48/e2107794118


Using rock physics models to validate rock composition from multimineral log analysis

L Cheng, M Prasad, RJ Michelena, A Tura, S Akther… - Geophysics, 2021


The Machine Learning's Classification Methods Comparison to Estimate Electrofacies Type, Lithology and Hydrocarbon Fluids from Geophysical Well Log Data

DA Panggabean, JH Arief, LK Muhtar, MN Alamsyah - 2021

Ivan Olier et al. ‘Transformational Machine Learning: Learning How to Learn from Many Related Scientific Problems.’ Proceedings of the National Academy of Sciences (2021). DOI: 10.1073/pnas.2108013118


Automating Workflows with GitHub Actions

 Read Now


Extending Power BI with Python and R

 Read Now


Machine Learning Engineering with Python

 Read Now



---

__Books


https://www.amazon.com/History-Statistics-Measurement-Uncertainty-before-ebook/dp/B08J7RJ3WN/ref=sr_1_1?crid=2EN841D6I7IF4&keywords=The+History+of+Statistics%3A+The+Measurement+of+Uncertainty+before+1900&qid=1644149706&s=books&sprefix=the+history+of+statistics+the+measurement+of+uncertainty+before+1900%2Cstripbooks-intl-ship%2C121&sr=1-1

https://www.amazon.com/Willful-Ignorance-Uncertainty-Herbert-Weisberg-ebook/dp/B00NBU9B6U/ref=sr_1_fkmr0_1?crid=2EN841D6I7IF4&keywords=The+History+of+Statistics%3A+The+Measurement+of+Uncertainty+before+1900&qid=1644149706&s=books&sprefix=the+history+of+statistics+the+measurement+of+uncertainty+before+1900%2Cstripbooks-intl-ship%2C121&sr=1-1-fkmr0

https://www.amazon.com/Rise-Statistical-Thinking-1820-1900/dp/0691208425/ref=sr_1_fkmr0_2?crid=2EN841D6I7IF4&keywords=The+History+of+Statistics%3A+The+Measurement+of+Uncertainty+before+1900&qid=1644150101&s=books&sprefix=the+history+of+statistics+the+measurement+of+uncertainty+before+1900%2Cstripbooks-intl-ship%2C121&sr=1-2-fkmr0

https://www.amazon.com/Dice-Play-God-Mathematics-Uncertainty-ebook/dp/B07LBQW3QX/ref=sr_1_fkmr1_1?crid=2EN841D6I7IF4&keywords=The+History+of+Statistics%3A+The+Measurement+of+Uncertainty+before+1900&qid=1644150101&s=books&sprefix=the+history+of+statistics+the+measurement+of+uncertainty+before+1900%2Cstripbooks-intl-ship%2C121&sr=1-1-fkmr1

https://www.amazon.com/Beyond-Measure-Physics-Philosophy-Meaning/dp/0198525362/ref=sr_1_1?crid=3W014N92U5SGI&keywords=beyond+measure+baggott&qid=1644150921&sprefix=beyond+measure+bag%2Caps%2C120&sr=8-1

### 03. Appendix A/Useful articles
- https://towardsdatascience.com/how-to-create-a-professional-github-data-science-repository-84e9607644a2
- https://towardsdatascience.com/how-to-create-a-professional-github-data-science-repository-84e9607644a2
- https://towardsdatascience.com/simulate-real-life-events-in-python-using-simpy-e6d9152a102f
- https://towardsdatascience.com/guide-to-classification-on-imbalanced-datasets-d6653aa5fa23
- https://towardsdatascience.com/how-to-create-mathematical-animations-like-3blue1brown-using-python-f571fb9da3d1
- https://towardsdatascience.com/how-to-easily-automate-your-python-scripts-on-mac-and-windows-459388c9cc94
- https://towardsdatascience.com/how-to-effortlessly-publish-your-python-package-to-pypi-using-poetry-44b305362f9f
- https://towardsdatascience.com/how-to-embed-your-julia-code-into-python-to-speed-up-performance-e3ff0a94b6e
- https://towardsdatascience.com/introduction-to-yellowbrick-a-python-library-to-explain-the-prediction-of-your-machine-learning-d63ecee10ecc
- https://towardsdatascience.com/how-to-leverage-visual-studio-code-for-your-data-science-projects-7078b70a72f0
- https://towardsdatascience.com/intro-to-open-database-for-geoscience-computing-part-1-of-2-2ad214fc2388
- https://towardsdatascience.com/the-essential-machine-learning-project-checklist-3ad6a7a49c37
- https://towardsdatascience.com/pywebio-write-interactive-web-app-in-script-way-using-python-14f50155af4e
- https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6
- https://towardsdatascience.com/normality-tests-in-python-31e04aa4f411
- https://towardsdatascience.com/jupyterlab-2-0-edd4155ab897
- https://towardsdatascience.com/3-must-have-jupyterlab-2-0-extensions-41024fe455cc
- https://github.com/tirthajyoti/Machine-Learning-with-Python
- https://infocus.github.com/
- https://github.com/git-guides/
- https://coderefinery.github.io/git-intro/
- https://github.com/BruceEckel/ThinkingInPython
- https://github.com/audreyfeldroy/cookiecutter-pypackage
- https://github.com/Avik-Jain/100-Days-Of-ML-Code
- https://github.com/realpython/python-guide
- https://github.com/cosmicpython/book
- https://github.com/swaroopch/byte-of-python
- https://github.com/rasbt/python-machine-learning-book-3rd-edition
- https://github.com/zhiwehu/Python-programming-exercises
- https://github.com/Raocp
- https://github.com/PyTorchLightning/pytorch-lightning
- https://github.com/microsoft/DeepSpeed
- https://github.com/nogueirs/JMLR2018
- https://github.com/facebookresearch/transformer-sequential
- https://github.com/interpretml/dice
- https://github.com/leanprover-community/mathlib
- https://github.com/nogueirs/JMLR2018
- https://github.com/gazprom-neft
- https://github.com/vanderschaarlab/mlforhealthlabpub/tree/main/alg/symbolic_metamodeling
- https://github.com/alan-turing-institute/the-turing-way
- https://github.com/best-practice-and-impact
- https://fairplus.github.io/the-fair-cookbook/content/home.html
- https://github.com/alan-turing-institute/the-turing-way
- https://github.com/bessagroup/F3DASM
- https://github.com/darioizzo/dcgp
- https://github.com/DEAP/deap
- https://github.com/fastai/fastbook
- https://github.com/jcrozum/PyStableMotifs
- https://github.com/verdverm/pypge
- https://softwaresaved.github.io/python-intermediate-development/
- https://medium.com/@andrea.castiglioni
- https://medium.com/topic/data-science
- https://levelup.gitconnected.com/more-than-thirty-machine-learning-blogs-and-newsletters-that-increased-our-productivity-3825b6b042e2
- https://medium.com/analytics-vidhya/machine-learning-project-checklist-56c549ac6712
- https://medium.com/swlh/10-tips-for-writing-scientific-papers-8c60ae18fed2
- https://medium.com/abzuai/the-qlattice-a-new-machine-learning-model-you-didnt-know-you-needed-c2e037878cd
- https://medium.com/swlh/reading-100s-of-pdf-files-in-2-minutes-bf57b57ed7d2
- https://link.medium.com/cwoafqVzRdb
- https://link.medium.com/eGw4cLqvRdb
- https://karpathy.medium.com/icml-accepted-papers-institution-stats-bad8d2943f5d
- https://medium.com/data-analysis-center
- https://medium.com/@subpath/jupyter-lab-extensions-for-data-scientist-e0d97d529fc1
- https://medium.com/analytics-vidhya/python-symbolic-regression-with-gplearn-cbc24dbbc271



P3. Lære informatikk
--------------------
- @RISK
    + flere kurs
- Excel 
    + IF(ISFORMULA(A1), FORMULATEXT(A1), "")
- Linux 
    + find . -name "lfp_*"

P4. Petrofysikk i OB
--------------------

P5. SMDA
--------
- Arne Tjora

P6. Flytting til D1416A
-----------------------

P7. Geolog & confidensintervaller
---------------------------------
- Har spurt Olabode om dette

P8. Forbedre Kjosavik paper om relativ permeabilitet
----------------------------------------------------

P9. Struktur Linux
------------------
- .bashrc; cd $LFP hopper til LFP området i Linux
- lagt inn https://git-lfs.github.com
- lastet ned SRML etter denne

P10. Depth
----------
- Harald Bult sin bok
- 5-6 m skift mellom LWD og WL in Brazil




# Machine Learning and Science

Main resources:
- [2nd annual workshop on Knowledge Guided Machine Learning (2021)](https://sites.google.com/umn.edu/kgmlworkshop)
- [Agile blog](https://us6.campaign-archive.com/home/?u=3e1e2cd71eeb0422366e88354&id=1ddb57434a)
- [Neural Information Processing Systems (NIPS 1987)](https://proceedings.neurips.cc/paper/1987)
- [Projects to Know](https://projectstoknow.amplifypartners.com/ml-and-data)
- [Software Carpentries - Our Lessons](https://software-carpentry.org/lessons/)
- [Zulip, Coderefinery](https://coderefinery.zulipchat.com/#)

People:
- Bailey, William
  * https://www.researchgate.net/profile/William-Bailey-12
- Benson, Austin R.
  * https://www.cs.cornell.edu/~arb/
- Beurdouche, Héloïse
  * https://www.linkedin.com/in/h%C3%A9lo%C3%AFse-beurdouche-63678024/
- Boyd, Austin
  * https://www.researchgate.net/profile/Austin-Boyd-3
- Britton, Allen 
  * https://www.linkedin.com/in/allen-britton-a4b2b840/
- Cuddy, Steve 
  * https://www.linkedin.com/in/steve-cuddy-84780210/
- Datir, Harish
  * https://www.researchgate.net/profile/Harish-Datir
- Ferreira, Flavio
  * https://www.researchgate.net/profile/Flavio-Ferreira-9
- Gkortsas, Vasileios Marios
  * https://www.researchgate.net/profile/Vasileios-Marios-Gkortsas
- Jakubowicz, Waclaw 
  * https://www.linkedin.com/in/waclaw-jakubowicz-473a4a10/
- Johansen, Yngve
  * https://www.researchgate.net/profile/Yngve-Johansen
- Liang, Lin
  * https://www.researchgate.net/profile/Lin-Liang-15
- Lynch, Patrick 
  * https://www.linkedin.com/in/kpl23/
- Machado, Patrick 
  * https://www.researchgate.net/profile/Patrick-Machado-2
- McDonald, Andy
  * https://www.andymcdonald.scot/
  * https://www.andymcdonald.scot/portfolio/proj_python_petrophysics/
  * https://andymcdonaldgeo.medium.com/
  * https://www.linkedin.com/in/andymcdonaldgeo/
  * https://github.com/andymcdgeo
  * https://twitter.com/geoandymcd
- Mullins, Oliver
  * https://www.researchgate.net/profile/Oliver-Mullins
- Nes, Olav-Magnar
  * https://www.researchgate.net/profile/Olav-Magnar-Nes-2
- Nye, Rebecca 
  * https://www.linkedin.com/in/the-rebecca-nye/
- Phillips, Craig
  * https://github.com/Philliec459
- Pozo, John Masapanta
  * https://github.com/JohnMasapantaPozo
- Prado, Augustin
  * https://www.researchgate.net/profile/Augustin-Prado
- Pyrcz, Michael
  * https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig/featured
  * https://direct.pge.utexas.edu/home
  * https://github.com/GeostatsGuy
  * https://twitter.com/geostatsguy
- Rinna, 
  * https://www.researchgate.net/profile/Joachim-Rinna
- Schaub, Michael
  * https://michaelschaub.github.io/
- Silva, Marianna Dantas da
  * https://www.researchgate.net/profile/Marianna-Dantas-Da-Silva-2
- Simones, Vanessa
  * https://www.researchgate.net/profile/Vanessa-Simoes-3
- Snow, Cameron 
  * https://www.linkedin.com/in/cameron-snow-981770b/
- Stovas, Alexey
  * https://www.researchgate.net/profile/Alexey-Stovas
- Stukan, Mikhail
  * https://www.researchgate.net/profile/Mikhail-Stukan
- Tilke, Peter
  * https://www.researchgate.net/profile/Peter-Tilke
- Venkataramanan, Lalitha 
  * https://www.linkedin.com/in/lalitha-venkataramanan/
  * https://youtu.be/ZfECTKuXdtw
- Zhang, Tuanfeng
  * https://www.researchgate.net/profile/Tuanfeng-Zhang


Resource Book
===

4.Competitions
---

- [pddasig, deadline 15th oct 2021](https://github.com/pddasig/Machine-Learning-Competition-2021)
- [SPEGCS/ML_Challenge, Feb 2021](https://github.com/SPEGCS/ML-Challenge-Feb-March-2021)

5.Education
---

- [23andMe](https://www.23andme.com/en-int/)
- [ACM](https://www.acm.org); member 1870120
- [AHRS](https://www.ancient-hebrew.org)

Appendix D - Misc ideas and concepts
---

- Elliott-Halberstam conjecture
- Euler totient function
- fuzzy set
- graph isomorphic problem
- Klein Imposibility Theorem for Clustering
- Lubell-Yamamoto-Meshalkin inequality
- Møbius group
- pigenhole principle
- pimbook.org
- Polymath project
- principle of inclusion-exclusion
- proof by induction, contradiction
- https://www.akalin.com/quintic-unsolvability
- RSA group
- Schlafli symbol
- Sperner family
- Steiner system
- @TilingBot
- Wilkinson's polynomial
- Zermelo-Fraenkel axioms

Appendix E - General Database
---

AI Researchers and Enthusiasts
- https://app.slack.com/client/T3D5HB2HH/C3D7GC2CS

AI Wiki
- https://wiki.pathmind.com/python-ai

AI-Feynman
- https://github.com/SJ001/AI-Feynman
	
AI-Pool
- https://ai-pool.com/

Alibi Detect
- https://docs.seldon.io/projects/alibi-detect/en/stable/index.html

ALON Bible
- https://alonbible.com/

Alphafold
- https://alphafold.ebi.ac.uk/

Alphafold2
- https://www.blopig.com/blog/2021/07/alphafold-2-is-here-whats-behind-the-structure-prediction-miracle/
- https://github.com/deepmind/alphafold

Anaconda
- ANACONDA_URL = "https://anaconda.cloud/sign-in"
- ANACONDA_USERNAME = "ingehap@gmail.com"
- ANACONDA_PASSWORD = "Lillian77!!"

Applied Machine Learning
- https://appliedmachinelearning.blog/

arXiv e-mail alert
- https://arxiv.org/help/subscribe

ArXiv-sanity
- http://arxiv-sanity.com/

Astroautomata
- https://astroautomata.com//blog/simulation-based-inference/
- https://astroautomata.com//paper/lagrangian-neural-networks/

AWKNG School
- https://awkngschooloftheology.com/

AWOL
- ancientworldonline.blogspot.com

BetterProgramming
- https://betterprogramming.pub/

Bibelen 2011 (Bokmål)
- https://biblia.com

Bibelnerden
- https://bibelnerden.no/blog/

BibleProject - YouTube
- https://www.youtube.com/channel/UCVfwlh9XpX2Y_tQfjeln9QA
- https://bibleproject.com/

Biblingual - YouTube
- https://www.youtube.com/channel/UCV1LtdcOJxsbqa_ELLe4gRw/featured

BioLogos
- https://biologos.org

Bitpipe
- BITPIPE_URL = "https://www.bitpipe.com/"
- BITPIPE_USERNAME = "ingehap@gmail.com"
- BITPIPE_PASSWORD = "Lillian77!!"

black

BLIS
- https://github.com/flame/blis

BlockWatne, Min side
- https://minside.blockwatne.no/bolig/10189041203

bookis
- https://bookis.com/no/

Broer score
- https://en.wikipedia.org/wiki/Brier_score

Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm
- https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm

bruges
- https://agilescientific.com/bruges/

calysto scheme  
- https://github.com/Calysto/calysto_scheme

Cantera
- https://cantera.org

Carpentries - Community Developed Lessons
- https://carpentries.org/community-lessons/

Carpentries-Incubator - Workflows with Python and Git
- https://carpentries-incubator.github.io/swc-ext-python/
- https://github.com/carpentries-incubator/

Carpentries-Lab
- https://github.com/carpentries-lab

CatalyzeX

- https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpam-idigaffhfmgbkdeheil

cgal
- https://www.cgal.org/index.html

CGG Geoverse database
- https://sway.office.com/XCK2ISlQSEPhC0Wh

CGG Webinars
- WATCH THE VIDEO RECORDING

Citation file format
- https://github.com/citation-file-format/citation-file-format
- https://citation-file-format.github.io/

clustergram
- https://pypi.org/project/clustergram/

CMC Markets
- https://oaf.cmcmarkets.com/no-no/onboarding/no/demo?utm_source=E24&utm_medium=display&utm_campaign=no-dr-07-2021&utm_term=direct&utm_content=9-tips-short

CodeRefinery
- https://coderefinery.github.io/git-intro/

Cookiecutter
- https://cookiecutter.readthedocs.io/en/latest/README.html
- https://github.com/audreyfeldroy/cookiecutter-pypackage
	
CoreLab (8a4DnpHs)
- https://data.corelab.com/#view/dashboard
- CORELAB_URL = "https://data.corelab.com"
- CORELAB_USERNAME = "ipettersen"
- CORELAB_PASSWORD = "u2WKkmQR"

Courses
- Coursera, Getting started with Google Workspace
- Cornell, 
    * CS4220 - https://www.cs.cornell.edu/courses/cs4220/2021sp/
	* CS6210 - https://www.cs.cornell.edu/courses/cs6210/2020fa/
	* CS6241 - https://www.cs.cornell.edu/courses/cs6241/2019sp/

Crypto
- https://marketcap.com/
- https://miraiex.com/blog/sparer-til-pensjon-i-kryptovaluta/

CSNTM
- https://www.csntm.org/

data distribution
- https://towardsdatascience.com/identify-your-datas-distribution-d76062fc0802

data science platforms
- https://clear.ml/
- https://www.iguazio.com/
- https://www.dataiku.com/
- https://www.datarobot.com/
- https://www.h2o.ai/
- https://www.pachyderm.com/
- https://polyaxon.com/
- http://valohai.com/
- https://cnvrg.io/
- https://algorithmia.com/

data-science-hub slack
- https://app.slack.com/client/T0103AQC1BN/C013M9S6PC1

DataCamp
- https://datacamp.com

DataQuest
- https://www.catalyzex.com/
- https://community.dataquest.io/
- DATAQUEST_URL = "https://app.dataquest.io/login"

DataTalks.Club (Slack)
- https://app.slack.com/client/T01ATQK62F8/C01BQC114P2

Deep AI
- https://deepai.org/

DeepDyve
- https://www.deepdyve.com/
- https://blog.deepdyve.com/2021/06/07/how-to-do-a-systematic-literature-review-with-deepdyve/

DigitalNorway
- DIGITALNORWAY_URL = "https://digitalnorway.com/wp-login.php"
- DIGITALNORWAY_USERNAME = "ingehap@gmail.com"
- DIGITALNORWAY_PASSWORD = "kyNHt*5RKrvRmLin"

Dine penger
- https://www.dinepenger.no

Dinside
- https://dinside.dagbladet.no

dirty-cat
- https://dirty-cat.github.io/stable/

DnB, VISA
- Visa kort no = 4946 5600 1298 5836
- Dato = 02/2024
- Code = 070

DOIs
- Independent of the paper, different research objects can be published online on servers that offer DOIs. Some of these servers are 
    * Zenodo and FigShare (figures, presentations and reports)
	* Data Dryad (for data), 
	* Open Grants (for grant proposals) and 
	* Open Science Framework (OSF) (components of an open research project)

DPhi
- https://dphi.tech/courses/

E24
- https://e24.no

E24+
- https://e24.no/pluss

E24 Aksjelive
- https://aksjelive.e24.no

E24 Børs
- https://bors.e24.no/#!/market/world

EAGE
- EAGE Channel (YouYube)
- https://www.youtube.com/user/EAGEchannel/playlists
- Membership Number is M2006-0845
- EAGE_URL = "https://login.eage.org/"
- EAGE_USERNAME = "ingehap@gmail.com"
- EAGE_PASSWORD = "Lillian77!!"

Ecole de Physique des Houches
- https://www.youtube.com/c/EcoledePhysiquedesHouches/featured

Effective Computation in Physics
- https://github.com/physics-codes

Encyclopedia of Mathematical Geosciences
- https://link.springer.com/referencework/10.1007/978-3-030-26050-7

Exploration Library
- \\statoil.net\dfs\common\EXP\UK_Europe\UK\UKCS_Regional\Library

Finansportalen
- https://www.finansportalen.no/

Finxter
- https://blog.finxter.com/

FORCE
- https://www.youtube.com/playlist?list=PLQRq8gtBBwehYjV1l6boG33WPT-WO1y4Z

Foster, John
- https://www.youtube.com/channel/UCuYjtIdSaKZL-yXOI-JXKXA/videos
- https://github.com/johntfoster?tab=repositories

geocomp-0118
- https://github.com/helgegn/geocomp-0118


Geolog
- Petrophysical Tricks; [Watch Recording](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fattendee.gotowebinar.com%2Frecording%2FviewRecording%2F8830724755460613901%2F942532570312367368%2Finp%40equinor.com%3FregistrantKey%3D1094644505390393612%26type%3DABSENTEEEMAILRECORDINGLINK&data=04%7C01%7Cinp%40equinor.com%7C1ecb1fa089b447940d2708d952aa18e7%7C3aa4a235b6e248d591957fcf05b459b0%7C0%7C0%7C637631712788642763%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=cBpXQQu5JthY1mbEoDsdCXvfFgfu5Rz8s6CXk%2BJhBVQ%3D&reserved=0)
- Printing reset for new version
![Print set-up](https://i.imgur.com/GP7y9vG.png)
- Geolog Tips & Tricks
    * https://statoilsrm.sharepoint.com/sites/GeologPortal/SitePages/Tips-and-Tricks.aspx?web=1
	
	* Load in: Text importer; Interpolation = Tops; pick_identifier -> TOPS  
	* Export: Well Catalog; Panel / show Search

	* Security
	  + alle filer og kataloger assosiert med interface må skrivebeskyttes og den eneste med skrivetilgang er Geolog support.
	  + når Geolog oppdateres, skal følgende filer og kataloger overføres til loglan katalogen i den nye versjonen
	  + ved endring av Geolog sin Python versjon og/eller ved endring i TensorFlow versjon bør det offisielle test-case kjøres
	  + Et testcase med inputlogger og forventede resultater legges i roten på katalog
	  + ved endring av lokasjon for Geolog softwaren, må stien til ML modellene endres i samsvar til ny lokasjon.


Global Tax Justice
- https://www.globaltaxjustice.org/en/home

Google ML
- New Coursera specialization
- Hands On Machine Learning with Google Cloud Labs
    * Google -  Cloud
	https://cloud.google.com
	* Google - Colab
	https://colab.research.google.com/notebooks/intro.ipynb
	* Google - Kaggle
	https://www.kaggle.com

Hebrew Today
- https://hebrewtoday.com/

Heiser, Michael
- http://drmsh.com

HeuristicLab
- https://dev.heuristiclab.com/trac.fcgi/

Hugo (web page generator)
- https://gohugo.io/

Huseiernes Landsforbund
- http://huseierne.no

Hylleraas Centre for Quantum Molecular Sciences
- https://www.mn.uio.no/hylleraas/english/news-and-events/news/2021/

ICIJ
- https://www.icij.org/

IEEE Explore
- https://ieeexplore.ieee.org/Xplore/home.jsp

IHS Markit Energy Login
- IHS_URL = "https://my.ihs.com/Energy?ForceLogin=True"
- IHS_USERNAME = "inp@equinor.com"
- IHS_PASSWORD = "Lillian77!!"

IKEA Family
- https://www.ikea.com/no/no/ikea-family/

IMPORT AI
- https://jack-clark.net/

In charge 6
- https://www.gomibo.no/en/accessory-detail/incharge-6-gold

Internet, SP
- INTERNET_SP_USERNAME = "GET-FC9936"
- INTERNET_SP_PASSWORD = "51095765"

ipygany
- https://blog.jupyter.org/ipygany-jupyter-into-the-third-dimension-29a97597fc33

ISLR tidymodels LAB
- https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/

Israel Bible  Center
- https://weekly.israelbiblecenter.com
- https://israelbiblecenter.com/

Israel Institute of Biblical Studies
- https://israelbiblicalstudies.com
- https://blog.israelbiblicalstudies.com

JerusalemPerspective.com
- https://www.jerusalemperspective.com

JetBrains
- registration number = L5E9KSZ5LR 
- JETBRAINS_USERNAME = "inp_equinor
- JETBRAINS_SERVER = "http://jetbrainsls.equinor.com/"
- JETBRAINS_USERNAME = "inp_e- quinor"
- JETBRAINS_PASSWORD = "Alle1fugler"

Journal of Open Research Software

Journal of Open Source Software

Julia computing
- https://juliacomputing.com/

Julia newsletter
- https://newsletter.juliacomputing.com

Julia Sim
- https://juliacomputing.com/products/juliasim/

jupyter lab
- https://jlgjosue.medium.com/best-extensions-for-jupyterlab-185ab5f3e05c

Kaggle
- https://www.kaggle.com/
- User ID = 1697288

KGML2021
- Youtube: https://z.umn.edu/kgmlworkshopyoutube21

Kjemi Digital
- www.kjemidigital.no

Laconic Machine Learning
- https://laconicml.com/

lasio

LearningGeoscience
- https://learninggeoscience.org/login/index.php

learnpython.org
- https://www.learnpython.org

Les Houches
- https://www.youtube.com/playlist?list=PLo9ufcrEqwWHUlFCf1P5rUGKbqNgCXZe8

Living Review of Machine Learning for Particle Physics
- https://iml-wg.github.io/HEPML-LivingReview/

Logos
- https://www.logos.com/
- Logos Blog
    * https://blog.logos.com

Machine Learning and Dynamical Systems Seminars
- https://www.youtube.com/channel/UCetvKhuAbnuU1tidgCz9g0g/videos

Machine Learning Mastery
- https://machinelearningmastery.com/
- https://machinelearningmastery.com/parametric-statistical-significance-tests-in-python/

Machine Learning Repository
- https://archive.ics.uci.edu/ml/index.php

Madagascar
- http://www.ahay.org
- https://reproducibility.org/wiki/Guide_to_programming_with_madagascar

Maier, Andreas
- https://lme.tf.fau.de/teaching/free-deep-learning-resources/

Matlab Unix (Stavanger)
- Run matlab from "/prog/matlab/R2020B/bin".

matplotlib

Memra Online
- http://www.memraonline.com/allcourses.html

Mendeley Document Manager
- MENDELEY_URL = "https://www.mendeley.com/reference-manager/library/all-references/"
- MENDELEY_USERNAME = "ingehap@gmail.com"
- MENDELEY_PASSWORD = "lillian7"

Merely Useful
- https://github.com/orgs/merely-useful/repositories

Michigan Online
- https://online.umich.edu/

Microsoft 
- Microsoft Education
	https://docs.microsoft.com/en-us/learn/browse/
- Microsoft Research Blog
	https://www.microsoft.com/en-us/research/blog/

MIGRI
- MIGRI_URL = "https://migris.no/userguide/"
- MIGRI_USERNAME = "migrino"
- MIGRI_PASSWORD = "migri.no"

MixMatch
- https://towardsdatascience.com/a-fastai-pytorch-implementation-of-mixmatch-314bb30d0f99
- https://github.com/google-research/mixmatch

ML YouTube Courses
- https://github.com/dair-ai/ML-YouTube-Courses

mlbox
- https://mlbox.readthedocs.io/en/latest/introduction.html

MobaXterm
- https://mobaxterm.mobatek.net/download.html
- Running powerful Unix CLI on Windows

Multi-Scale Rock Physics Research Program
- https://sites.utexas.edu/ultrapetrophysics/
- https://iap.cpge.utexas.edu/msrp/msrp2020.html
- https://iap.cpge.utexas.edu/msrp/msrp2021.html 
- (The user name is: UltraPetrophysics-2021, Password is: MultiScale.21)

Mwiti, Derrick
- https://cnvrg.io/hyperparameter-tuning/
- https://cnvrg.io/author/derrickm/

Naked Bible Podcast
- https://nakedbiblepodcast.com/

NET Bible
- https://netbible.org/bible/Matthew+1   

NIPS
- Advances in Neural Information Processing Systems 33 (NeurIPS 2020)
- Advances in Neural Information Processing Systems 32 (NeurIPS 2019)
- Advances in Neural Information Processing Systems 31 (NeurIPS 2018)
- Advances in Neural Information Processing Systems 30 (NIPS 2017)
- Advances in Neural Information Processing Systems 29 (NIPS 2016)
- Advances in Neural Information Processing Systems 28 (NIPS 2015)
- Advances in Neural Information Processing Systems 27 (NIPS 2014)
- Advances in Neural Information Processing Systems 26 (NIPS 2013)
- Advances in Neural Information Processing Systems 25 (NIPS 2012)
- Advances in Neural Information Processing Systems 24 (NIPS 2011)
- Advances in Neural Information Processing Systems 23 (NIPS 2010)
- Advances in Neural Information Processing Systems 22 (NIPS 2009)
- Advances in Neural Information Processing Systems 21 (NIPS 2008)
- Advances in Neural Information Processing Systems 20 (NIPS 2007)
- Advances in Neural Information Processing Systems 19 (NIPS 2006)
- Advances in Neural Information Processing Systems 18 (NIPS 2005)
- Advances in Neural Information Processing Systems 17 (NIPS 2004)
- Advances in Neural Information Processing Systems 16 (NIPS 2003)
- Advances in Neural Information Processing Systems 15 (NIPS 2002)
- Advances in Neural Information Processing Systems 14 (NIPS 2001)
- Advances in Neural Information Processing Systems 13 (NIPS 2000)
- Advances in Neural Information Processing Systems 12 (NIPS 1999)
- Advances in Neural Information Processing Systems 11 (NIPS 1998)
- Advances in Neural Information Processing Systems 10 (NIPS 1997)
- Advances in Neural Information Processing Systems 9 (NIPS 1996)
- Advances in Neural Information Processing Systems 8 (NIPS 1995)
- Advances in Neural Information Processing Systems 7 (NIPS 1994)
- Advances in Neural Information Processing Systems 6 (NIPS 1993)
- Advances in Neural Information Processing Systems 5 (NIPS 1992)
- Advances in Neural Information Processing Systems 4 (NIPS 1991)
- Advances in Neural Information Processing Systems 3 (NIPS 1990)
- Advances in Neural Information Processing Systems 2 (NIPS 1989)
- Advances in Neural Information Processing Systems 1 (NIPS 1988)

NMR
- https://rockphysicstechnology.com/

NPTEL
- https://www.youtube.com/c/iit/playlists
- https://nptel.ac.in/noc/noc_course.html

numpy

NVIDIA Developers Blog
- https://developer.nvidia.com/blog/

OBOS Bank, konto
- https://bank.obos.no/
Konto numm- er = 9820 32 83067

OBOS Bank, kort
- 4052 0800 2177 6530, 08/24, INGE HERMOD ASKL PETTERSEN, 469

ObsPy
- https://github.com/obspy/obspy/wiki
- seismology

ODSC Global slack
- https://app.slack.com/client/TKGLEV1LM/browse-channels

OPC
- https://open.spotify.com/show/17XrNFfClRRVP3s9ac5fpT

Open Data Science (OSDC) Categories
- https://opendatascience.com/category/academic-research/
- https://opendatascience.com/category/conferences/odsc-speaker/
- https://opendatascience.com/category/modeling/deep-learning/
- https://opendatascience.com/category/modeling/machine-learning/
- https://opendatascience.com/category/modeling/nlp-text-analytics/
- https://opendatascience.com/category/modeling/research-modeling/
- https://opendatascience.com/category/modeling/statistics/
- https://opendatascience.com/category/tools-languages/workflow/
- https://app.slack.com/client/TKGLEV1LM/learning-slack
- https://medium.com/odscjournal

Open Doors
- https://www.opendoors.no/

OpendTect
- https://dgbes.com/index.php/download

OpenKIM
- https://openkim.org/browse/models/alphabetical

Optimalization
- https://github.com/uber-research/TuRBO
- https://github.com/hyperopt/hyperopt
- https://scikit-optimize.github.io/stable/

OutWit Hub
- https://www.outwit.com/products/hub/OutWit-Hub-Light-Pro-Expert-Enterprise-editions

palabos; fluid flow
- https://palabos.unige.ch/
- https://gitlab.com/unigespc/palabos

pandas
- Pandas documentation
	https://pandas.pydata.org/pandas-docs/stable/
- Pandas source
	https://github.com/pandas-dev/pandas/tree/master/doc

pathlib

Penger.no
- https://penger.no

Pensjonistforbundet
- www.pensjonistforbundet.no
- Ditt medlemsnummer er 40292682 

People analytics regression book
- https://github.com/keithmcnulty/peopleanalytics-regression-book

petrophysics / predicting logs by ML
- https://towardsdatascience.com/prediction-of-p-sonic-log-in-the-volve-oil-field-using-machine-learning-9a4afdb92fe8
- https://towardsdatascience.com/petrophysics-gamma-ray-normalization-in-python-9a67a335dbd

Physics Informed DL
- https://maziarraissi.github.io/research/1_physics_informed_neural_networks/
- https://github.com/thunil/Physics-Based-Deep-Learning
- https://github.com/SciML/
- https://sciml.ai/

pillow

Pragmatic Bookshelf
- https://pragprog.com/

precipNet
- https://github.com/rmcgranaghan/precipNet
	
Privatdozent
- https://www.privatdozent.co/

Project Management
- Principles
	* https://coderefinery.github.io/reproducible-research/02-organizing-projects/
- Place for code
	* https://github.com:
	* https://gitlab.com: public or private repositories
	* https://source.coderefinery.org

PyCaret
- https://www.learndatasci.com/tutorials/introduction-pycaret-machine-learning/

PyData Global Talks
- https://courses.numfocus.org/courses/course-v1:PyDataGlobal+PDG20-talks+2020/about

pylint

PySIT 
- http://pysit.readthedocs.io/en/stable/index.html
- seismic inversion

pytest
- API reference
- https://docs.pytest.org/en/6.2.x/reference.html

python software carpentry, 10-11 Nov 2020
- https://www.youtube.com/playlist?list=PLpX1jXuNTXGoDO5vuHR_pSyxNBr_M233-

python-crontab 
- read and write crontab files

pythoncheatsheet
- https://www.pythoncheatsheet.org/

python for scientific computing
- https://aaltoscicomp.github.io/python-for-scicomp/

Python in Equinor
- https://statoilsrm.sharepoint.com/sites/InstallingPython/SitePages/Creating-virtual-environments.aspx
- Installing Python on Windows 
	* https://statoilsrm.sharepoint.com/sites/InstallingPython/SitePages/Installing-Python-Windows.aspx
- Installing additional Python packages on Windows
	* https://statoilsrm.sharepoint.com/sites/InstallingPython/SitePages/Installing-additional-Python-packages-on-Windows.aspx

Python Wiki
- https://wiki.python.org/moin/

pyttsx3
- https://pyttsx3.readthedocs.io/en/latest/

Quant Finance
- https://informaconnect.com/quant-finance/

R Discovery
- R_Discovery_URL = "https://discovery.researcher.life/home"
- R_Discovery_USERNAME = "ingehap@gmail.com"
- R_Discovery_PASSWORD = "lillian7"

R Upskill
- you can manage your membership here 
- https://upskill.researcher.life/my-account/manage-subscription/  
- Plan type: R Upskill Membership – Monthly plan $9 

RealPython
- https://realpython.com
- https://realpython.com/start-contributing-python/
- https://realpython.com/python-sql-libraries/
- https://realpython.com/documenting-python-code/
- RealPython_URL = "https://realpython.com/"
- RealPython_USERNAME = "ingehap@gmail.com"
- RealPython_PASSWORD = "lillian7"

requests
- Requests documentation
- https://docs.python-requests.org/en/master/
- Requests source
- https://github.com/psf/requests/tree/master/docs

Research Bazar
- https://resbazblog.wordpress.com/

Research.com
- https://research.com/

Samordna Opptak
- https://www.samordnaopptak.no/info/

SaltNet
- https://library.seg.org/doi/abs/10.1190/tle39030195.1

Sbanken, kontoer
- Konto #1 - 9713 22 23 584 (Visa)
- Konto #2 - 9713 22 23 630

Sbanken, kort
- 4569 9710 6403 2482, INGE H. A. PETTERSEN, 04/24, 898

Schlumberger Curve Mnemonic Dictionary
- https://www.apps.slb.com/cmd/index.aspx

scipy

scopus
- SCOPUS_URL = "https://www.scopus.com/"
- SCOPUS_USERNAME = "inp@equinor.com"
- SCOPUS_PASSWORD = "lillian7"

SEG
- SEG eBooks
- https://library.seg.org/book/marc
- SEG Knowledgette
- https://www.knowledgette.com/courses/category/SEG
- SEG Lectures
- https://library.seg.org/e-learning/lectures
- SEG on Demand
- https://seg.org/Education/SEG-on-Demand
- SEG_URL = "https://seg.org/Default.aspx"
- SEG_USERNAME = "ingehap@gmail.com"
- SEG_PASSWORD = "Alle7Fugler8Smaa"

seg/tutorials-2018
- https://github.com/seg/tutorials-2018

Sequence
- https://thesequence.substack.com/archive

Serenity Prayer - Wikipedia
- https://en.wikipedia.org/wiki/Serenity_Prayer

ServiceNow Equinor Production System
- https://equinor.service-now.com/nav_to.do?uri=%2Ftask_list.do%3Fsysparm_userpref_module%3D1523b8d4c611227b00be8216ec331b9a%26sysparm_query%3Dactive%3Dtrue%5Eassigned_to%3Djavascript:getMyAssignments()%5EstateNOT%2BIN6,5%5EEQ%26sysparm_clear_stack%3Dtrue

SIAM
	User ID = 001019878
	Proc. 2021 SIAM Int. Conf. on Data Mining (SDM)
	https://epubs.siam.org/doi/book/10.1137/1.9781611976700
	SIAM Conferences on YouTube
	https://www.youtube.com/watch?v=1biep1Rh_08
	SIAM News
	https://sinews.siam.org/Current-Issue/Issue-Archives
	DL & PDE
	https://sinews.siam.org/Details-Page/new-bridges-between-deep-learning-and-partial-differential-equations

SILO closed Google Group
	https://groups.google.com/a/g-groups.wisc.edu/g/silo

SlidesLive
	https://library.slideslive.com/

snakemake
	https://snakemake.readthedocs.io/en/stable/getting_started/installation.html

Software Sustainability Institute
	https://www.youtube.com/c/SoftwareSaved/playlists

SoloLearn
          https://www.sololearn.com/

Source Rock Machine Learning 
          https://github.com/equinor/SRML/

sphinx
	https://sphinx-tutorial.readthedocs.io/

SPWLA
          https://github.com/Amrmoslim/SPWLA_Webinar_Jan_2021
          https://github.com/SPWLA-ORG/spwla2021_ml_workshop
          https://github.com/zsylvester/meanderpy
          https://github.com/toddheitmann/petropy
          https://github.com/seg/2016-ml-contest
          https://github.com/brendonhall/FORCE-2020-Lithology
          https://www.youtube.com/channel/UCuY_meTb65lYmGSUNLzj-IA
          https://www.youtube.com/channel/UC4nGM9WrCaiZ3jQu9FzU2Sg
           https://github.com/pddasig
           SPWLA 2021
           https://pheedloop.com/spwla2021/login/auth/?redirect=/spwla2021/virtual/
           Email: ingehap@gmail.com   Password:gNpvfJncO@

Stack Abuse - Python
	https://stackabuse.com/tag/python/

Structure and Interpretation of Computer Programs
	http://sarabander.github.io/sicp/html/index.xhtml
	https://www.neilvandyke.org/sicp-texi/

Subsurface Excellence and Digital Communication Site
	https://statoilsrm.sharepoint.com/sites/subexd
    
Synthetic Sonic Log Generation With Machine Learning: A Contest Summary From Five Methods

TalkPython
	https://training.talkpython.fm/

ternary plot
           https://towardsdatascience.com/basics-of-ternary-plots-with-pythons-plotly-e5990ea399a5
           https://en.wikipedia.org/wiki/Ternary_plot
           https://plotly.com/python/ternary-plots/
           https://stackoverflow.com/questions/29512046/how-to-create-ternary-contour-plot-in-python

Theology
	https://en.wikipedia.org/wiki/Annihilationism
	https://en.wikipedia.org/wiki/Christian_conditionalism
	https://en.wikipedia.org/wiki/Christian_mortalism
	https://www.amazon.com/Julia-Blum/e/B00LUY0JN8

TheSequence
	https://thesequence.substack.com/archive

Towards AI
	https://pub.towardsai.net/

Tryo Labs
	https://tryolabs.com/blog/

TuringBot
	https://turingbotsoftware.com/blog/
	https://turingbotsoftware.com/

Uber engineering
	https://eng.uber.com/

Udemy
           https://www.udemy.com/

University of Bergen
	Theses @ Library, https://www.uib.no/en/ub

UTAPWeLS
	Equinor Wiki; https://wiki.equinor.com/wiki/index.php/Petrophysics:Software:UTAPWeLS
	YouTube; https://www.youtube.com/channel/UCHWnztyGyQPEXXbp2Tu0_DA/videos

voila 
          notebook as app

Weka
          https://www.cs.waikato.ac.nz/ml/weka/

Western Profile
	https://library.seg.org/page/western-profile

WikiProject Mathematics
          https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Mathematics

Wikipedia, Social psychology
          https://en.wikipedia.org/wiki/Social_psychology

WikiProject Statistics
          https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Statistics

World Wealth Report
	https://worldwealthreport.com

Wolfram Mathworld
          https://mathworld.wolfram.com/CatalansConstant.html

wrighters.io
	https://www.wrighters.io/parameters-jupyter-notebooks-with-papermill/?utm_campaign=Data_Elixir&utm_source=Data_Elixir_344
	
XEEK
	XEEK_URL = "https://xeek.ai/"
	XEEK_USERNAME = "inp@equinor.com"
	XEEK_PASSWORD = "Allefuglersmaa1!"


2020.carpentrycon.org
C-NLOPB
communicationtoolbox.equinor.com
esciencelab.org.uk
library.seg.org/toc/leedff/35/11
seg.org/newbooks
seg.org/education/lectures
seiscope2.osug.fr
tle.geoscience-world.org
www.HydrocarbonProcessing.com
www.iaa.bham.ac.uk
www.tleonline.org/theleadingedge
www.youtube.com/user/segeophysicists/playlists
www.oxfordhandbooks.com


# General Database

[![hackmd-github-sync-badge](https://hackmd.io/wJr6tXhpRoKH_tINw643Dw/badge)](https://hackmd.io/wJr6tXhpRoKH_tINw643Dw)


AI Researchers and Enthusiasts
- https://app.slack.com/client/T3D5HB2HH/C3D7GC2CS

AI Wiki
- https://wiki.pathmind.com/python-ai

AI-Feynman
- https://github.com/SJ001/AI-Feynman
	
AI-Pool
- https://ai-pool.com/

Alibi Detect
- https://docs.seldon.io/projects/alibi-detect/en/stable/index.html

ALON Bible
- https://alonbible.com/

Alphafold
- https://alphafold.ebi.ac.uk/

Alphafold2
- https://www.blopig.com/blog/2021/07/alphafold-2-is-here-whats-behind-the-structure-prediction-miracle/
- https://github.com/deepmind/alphafold

Anaconda
- ANACONDA_URL = "https://anaconda.cloud/sign-in"
- ANACONDA_USERNAME = "ingehap@gmail.com"
- ANACONDA_PASSWORD = "Lillian77!!"

Applied Machine Learning
- https://appliedmachinelearning.blog/

arXiv e-mail alert
- https://arxiv.org/help/subscribe

ArXiv-sanity
- http://arxiv-sanity.com/

Astroautomata
- https://astroautomata.com//blog/simulation-based-inference/
- https://astroautomata.com//paper/lagrangian-neural-networks/

AWKNG School
- https://awkngschooloftheology.com/

AWOL
- ancientworldonline.blogspot.com

BetterProgramming
- https://betterprogramming.pub/

Bibelen 2011 (Bokmål)
- https://biblia.com

Bibelnerden
- https://bibelnerden.no/blog/

BibleProject - YouTube
- https://www.youtube.com/channel/UCVfwlh9XpX2Y_tQfjeln9QA
- https://bibleproject.com/

Biblingual - YouTube
- https://www.youtube.com/channel/UCV1LtdcOJxsbqa_ELLe4gRw/featured

BioLogos
- https://biologos.org

Bitpipe
- BITPIPE_URL = "https://www.bitpipe.com/"
- BITPIPE_USERNAME = "ingehap@gmail.com"
- BITPIPE_PASSWORD = "Lillian77!!"

black

BLIS
- https://github.com/flame/blis

BlockWatne, Min side
- https://minside.blockwatne.no/bolig/10189041203

bookis
- https://bookis.com/no/

Broer score
- https://en.wikipedia.org/wiki/Brier_score

Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm
- https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm

bruges
- https://agilescientific.com/bruges/

calysto scheme  
- https://github.com/Calysto/calysto_scheme

Cantera
- https://cantera.org

Carpentries - Community Developed Lessons
- https://carpentries.org/community-lessons/

Carpentries-Incubator - Workflows with Python and Git
- https://carpentries-incubator.github.io/swc-ext-python/
- https://github.com/carpentries-incubator/

Carpentries-Lab
- https://github.com/carpentries-lab

CatalyzeX

- https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpam-idigaffhfmgbkdeheil

cgal
- https://www.cgal.org/index.html

CGG Geoverse database
- https://sway.office.com/XCK2ISlQSEPhC0Wh

CGG Webinars
- WATCH THE VIDEO RECORDING

Citation file format
- https://github.com/citation-file-format/citation-file-format
- https://citation-file-format.github.io/

CiteSeerX
- https://citeseerx.ist.psu.edu/index

ClearML
- https://clearml.slack.com/
- https://clear.ml/
- Log into your ClearML Managed account
- Get access to our docs
- Watch a few videos to understand how to use ClearML
- Join our thriving community on Slack
- Signup for a free ClearML Hosted Service account.

clustergram
- https://pypi.org/project/clustergram/

CMC Markets
- https://oaf.cmcmarkets.com/no-no/onboarding/no/demo?utm_source=E24&utm_medium=display&utm_campaign=no-dr-07-2021&utm_term=direct&utm_content=9-tips-short

CodeRefinery
- https://coderefinery.github.io/git-intro/

Cookiecutter
- https://cookiecutter.readthedocs.io/en/latest/README.html
- https://github.com/audreyfeldroy/cookiecutter-pypackage
	
CoreLab (8a4DnpHs)
- https://data.corelab.com/#view/dashboard
- CORELAB_URL = "https://data.corelab.com"
- CORELAB_USERNAME = "ipettersen"
- CORELAB_PASSWORD = "u2WKkmQR"

Courses
- Coursera, Getting started with Google Workspace
- Cornell, 
    * CS4220 - https://www.cs.cornell.edu/courses/cs4220/2021sp/
	* CS6210 - https://www.cs.cornell.edu/courses/cs6210/2020fa/
	* CS6241 - https://www.cs.cornell.edu/courses/cs6241/2019sp/

Crypto
- https://marketcap.com/
- https://miraiex.com/blog/sparer-til-pensjon-i-kryptovaluta/

CSNTM
- https://www.csntm.org/

csv

data distribution
- https://towardsdatascience.com/identify-your-datas-distribution-d76062fc0802

data science platforms
- https://clear.ml/
- https://www.iguazio.com/
- https://www.dataiku.com/
- https://www.datarobot.com/
- https://www.h2o.ai/
- https://www.pachyderm.com/
- https://polyaxon.com/
- http://valohai.com/
- https://cnvrg.io/
- https://algorithmia.com/

data-science-hub slack
- https://app.slack.com/client/T0103AQC1BN/C013M9S6PC1

DataCamp
- https://datacamp.com

DataQuest
- https://www.catalyzex.com/
- https://community.dataquest.io/
- DATAQUEST_URL = "https://app.dataquest.io/login"

DataTalks.Club (Slack)
- https://app.slack.com/client/T01ATQK62F8/C01BQC114P2

Deep AI
- https://deepai.org/

DeepDyve
- https://www.deepdyve.com/
- https://blog.deepdyve.com/2021/06/07/how-to-do-a-systematic-literature-review-with-deepdyve/

DigitalNorway
- DIGITALNORWAY_URL = "https://digitalnorway.com/wp-login.php"
- DIGITALNORWAY_USERNAME = "ingehap@gmail.com"
- DIGITALNORWAY_PASSWORD = "kyNHt*5RKrvRmLin"

Dine penger
- https://www.dinepenger.no

Dinside
- https://dinside.dagbladet.no

dirty-cat
- https://dirty-cat.github.io/stable/

DnB, VISA
- Visa kort no = 4946 5600 1298 5836
- Dato = 02/2024
- Code = 070

DOIs
- Independent of the paper, different research objects can be published online on servers that offer DOIs. Some of these servers are 
    * Zenodo and FigShare (figures, presentations and reports)
	* Data Dryad (for data), 
	* Open Grants (for grant proposals) and 
	* Open Science Framework (OSF) (components of an open research project)

DPhi
- https://dphi.tech/courses/

DuoLingo
- https://www.duolingo.com/

E24
- https://e24.no
- https://e24.no/aktiver-realtidskurser?source=

E24+
- https://e24.no/pluss

E24 Aksjelive
- https://aksjelive.e24.no

E24 Børs
- https://bors.e24.no/#!/market/world

EAGE
- EAGE Channel (YouYube)
- https://www.youtube.com/user/EAGEchannel/playlists
- Membership Number is M2006-0845
- EAGE_URL = "https://login.eage.org/"
- EAGE_USERNAME = "ingehap@gmail.com"
- EAGE_PASSWORD = "Lillian77!!"

Ecole de Physique des Houches
- https://www.youtube.com/c/EcoledePhysiquedesHouches/featured

Edx
- https://www.edx.org/

Effective Computation in Physics
- https://github.com/physics-codes

Encyclopedia of Mathematical Geosciences
- https://link.springer.com/referencework/10.1007/978-3-030-26050-7

Exploration Library
- \\statoil.net\dfs\common\EXP\UK_Europe\UK\UKCS_Regional\Library

Finansportalen
- https://www.finansportalen.no/

Finxter
- https://blog.finxter.com/

FORCE
- https://www.youtube.com/playlist?list=PLQRq8gtBBwehYjV1l6boG33WPT-WO1y4Z

Foster, John
- https://www.youtube.com/channel/UCuYjtIdSaKZL-yXOI-JXKXA/videos
- https://github.com/johntfoster?tab=repositories

geocomp-0118
- https://github.com/helgegn/geocomp-0118


Geolog
- Petrophysical Tricks; [Watch Recording](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fattendee.gotowebinar.com%2Frecording%2FviewRecording%2F8830724755460613901%2F942532570312367368%2Finp%40equinor.com%3FregistrantKey%3D1094644505390393612%26type%3DABSENTEEEMAILRECORDINGLINK&data=04%7C01%7Cinp%40equinor.com%7C1ecb1fa089b447940d2708d952aa18e7%7C3aa4a235b6e248d591957fcf05b459b0%7C0%7C0%7C637631712788642763%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=cBpXQQu5JthY1mbEoDsdCXvfFgfu5Rz8s6CXk%2BJhBVQ%3D&reserved=0)
- Printing reset for new version
![Print set-up](https://i.imgur.com/GP7y9vG.png)
- Geolog Tips & Tricks
    * https://statoilsrm.sharepoint.com/sites/GeologPortal/SitePages/Tips-and-Tricks.aspx?web=1
	
	* Load in: Text importer; Interpolation = Tops; pick_identifier -> TOPS  
	* Export: Well Catalog; Panel / show Search

	* Security
	  + alle filer og kataloger assosiert med interface må skrivebeskyttes og den eneste med skrivetilgang er Geolog support.
	  + når Geolog oppdateres, skal følgende filer og kataloger overføres til loglan katalogen i den nye versjonen
	  + ved endring av Geolog sin Python versjon og/eller ved endring i TensorFlow versjon bør det offisielle test-case kjøres
	  + Et testcase med inputlogger og forventede resultater legges i roten på katalog
	  + ved endring av lokasjon for Geolog softwaren, må stien til ML modellene endres i samsvar til ny lokasjon.

GitHub
- https://sabs-r3.github.io/2020-software-engineering-day4/index.html
- https://sabs-r3.github.io/2020-software-engineering-day3/index.html
- https://sabs-r3.github.io/2020-software-engineering-day2/index.html
- https://sabs-r3.github.io/2020-software-engineering-day1/index.html
- https://github.com/tirthajyoti/Machine-Learning-with-Python
- https://github.com/SABS-R3
- https://infocus.github.com/
- https://github.com/git-guides/
- https://coderefinery.github.io/git-intro/
- https://github.com/BruceEckel/ThinkingInPython
- https://github.com/audreyfeldroy/cookiecutter-pypackage
- https://github.com/Avik-Jain/100-Days-Of-ML-Code
- https://github.com/realpython/python-guide
- https://github.com/cosmicpython/book
- https://github.com/swaroopch/byte-of-python
- https://github.com/rasbt/python-machine-learning-book-3rd-edition
- https://github.com/zhiwehu/Python-programming-exercises
- https://github.com/Raocp
- https://github.com/PyTorchLightning/pytorch-lightning
- https://github.com/microsoft/DeepSpeed
- https://github.com/nogueirs/JMLR2018
- https://github.com/facebookresearch/transformer-sequential
- https://github.com/interpretml/dice
- https://github.com/leanprover-community/mathlib
- https://github.com/nogueirs/JMLR2018
- https://github.com/gazprom-neft
- https://github.com/vanderschaarlab/mlforhealthlabpub/tree/main/alg/symbolic_metamodeling
- https://github.com/alan-turing-institute/the-turing-way
- https://github.com/best-practice-and-impact
- https://fairplus.github.io/the-fair-cookbook/content/home.html
- https://github.com/alan-turing-institute/the-turing-way
- https://github.com/bessagroup/F3DASM
- https://github.com/darioizzo/dcgp
- https://github.com/DEAP/deap
- https://github.com/fastai/fastbook
- https://github.com/jcrozum/PyStableMotifs
- https://github.com/verdverm/pypge
- https://softwaresaved.github.io/python-intermediate-development/

Global Tax Justice
- https://www.globaltaxjustice.org/en/home

Google ML
- New Coursera specialization
- Hands On Machine Learning with Google Cloud Labs
    * Google -  Cloud
	https://cloud.google.com
	* Google - Colab
	https://colab.research.google.com/notebooks/intro.ipynb
	* Google - Kaggle
	https://www.kaggle.com

GSL
- https://www.wikiwand.com/en/GNU_Scientific_Library

Hebrew Today
- https://hebrewtoday.com/

Heiser, Michael
- http://drmsh.com

HeuristicLab
- https://dev.heuristiclab.com/trac.fcgi/

Hugo (web page generator)
- https://gohugo.io/

Huseiernes Landsforbund
- http://huseierne.no

Hylleraas Centre for Quantum Molecular Sciences
- https://www.mn.uio.no/hylleraas/english/news-and-events/news/2021/

ICIJ
- https://www.icij.org/

IEEE Explore
- https://ieeexplore.ieee.org/Xplore/home.jsp

IHS Markit Energy Login
- IHS_URL = "https://my.ihs.com/Energy?ForceLogin=True"
- IHS_USERNAME = "inp@equinor.com"
- IHS_PASSWORD = "Lillian77!!"

IKEA Family
- https://www.ikea.com/no/no/ikea-family/

IMPORT AI
- https://jack-clark.net/

In charge 6
- https://www.gomibo.no/en/accessory-detail/incharge-6-gold

Internet, SP
- INTERNET_SP_USERNAME = "GET-FC9936"
- INTERNET_SP_PASSWORD = "51095765"

ipygany
- https://blog.jupyter.org/ipygany-jupyter-into-the-third-dimension-29a97597fc33

ipython

ISLR tidymodels LAB
- https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/

Israel Bible  Center
- https://weekly.israelbiblecenter.com
- https://israelbiblecenter.com/

Israel Institute of Biblical Studies
- https://israelbiblicalstudies.com
- https://blog.israelbiblicalstudies.com

JerusalemPerspective.com
- https://www.jerusalemperspective.com

JetBrains
- registration number = L5E9KSZ5LR 
- JETBRAINS_USERNAME = "inp_equinor
- JETBRAINS_SERVER = "http://jetbrainsls.equinor.com/"
- JETBRAINS_USERNAME = "inp_e- quinor"
- JETBRAINS_PASSWORD = "Alle1fugler"

Journal of Open Research Software

Journal of Open Source Software

Julia computing
- https://juliacomputing.com/

Julia newsletter
- https://newsletter.juliacomputing.com

Julia Sim
- https://juliacomputing.com/products/juliasim/

jupyter lab
- https://jlgjosue.medium.com/best-extensions-for-jupyterlab-185ab5f3e05c

Kaggle
- https://www.kaggle.com/
- User ID = 1697288

KGML2021
- Youtube: https://z.umn.edu/kgmlworkshopyoutube21

Kjemi Digital
- www.kjemidigital.no

Laconic Machine Learning
- https://laconicml.com/

lasio

LearningGeoscience
- https://learninggeoscience.org/login/index.php

learnpython.org
- https://www.learnpython.org

Les Houches
- https://www.youtube.com/playlist?list=PLo9ufcrEqwWHUlFCf1P5rUGKbqNgCXZe8

Living Review of Machine Learning for Particle Physics
- https://iml-wg.github.io/HEPML-LivingReview/

Logos
- https://www.logos.com/
- Logos Blog
    * https://blog.logos.com

LPS
- https://lps.org.uk/events/

Machine Learning and Dynamical Systems Seminars
- https://www.youtube.com/channel/UCetvKhuAbnuU1tidgCz9g0g/videos

Machine Learning Mastery
- https://machinelearningmastery.com/
- https://machinelearningmastery.com/parametric-statistical-significance-tests-in-python/

Machine Learning Repository
- https://archive.ics.uci.edu/ml/index.php

Madagascar
- http://www.ahay.org
- https://reproducibility.org/wiki/Guide_to_programming_with_madagascar

Maier, Andreas
- https://lme.tf.fau.de/teaching/free-deep-learning-resources/

Matlab Unix (Stavanger)
- Run matlab from "/prog/matlab/R2020B/bin".

matplotlib

Medium
- https://medium.com/@andrea.castiglioni
- https://medium.com/topic/data-science
- https://levelup.gitconnected.com/more-than-thirty-machine-learning-blogs-and-newsletters-that-increased-our-productivity-3825b6b042e2
- https://medium.com/analytics-vidhya/machine-learning-project-checklist-56c549ac6712
- https://medium.com/swlh/10-tips-for-writing-scientific-papers-8c60ae18fed2
- https://medium.com/abzuai/the-qlattice-a-new-machine-learning-model-you-didnt-know-you-needed-c2e037878cd
- https://medium.com/swlh/reading-100s-of-pdf-files-in-2-minutes-bf57b57ed7d2
- https://link.medium.com/cwoafqVzRdb
- https://link.medium.com/eGw4cLqvRdb
- https://karpathy.medium.com/icml-accepted-papers-institution-stats-bad8d2943f5d
- https://medium.com/data-analysis-center
- https://medium.com/@subpath/jupyter-lab-extensions-for-data-scientist-e0d97d529fc1
- https://medium.com/analytics-vidhya/python-symbolic-regression-with-gplearn-cbc24dbbc271

Memra Online
- http://www.memraonline.com/allcourses.html

Mendeley Document Manager
- MENDELEY_URL = "https://www.mendeley.com/reference-manager/library/all-references/"
- MENDELEY_USERNAME = "ingehap@gmail.com"
- MENDELEY_PASSWORD = "lillian7"

Merely Useful
- https://github.com/orgs/merely-useful/repositories

Michigan Online
- https://online.umich.edu/

Microsoft 
- Microsoft Education
	https://docs.microsoft.com/en-us/learn/browse/
- Microsoft Research Blog
	https://www.microsoft.com/en-us/research/blog/

MIGRI
- MIGRI_URL = "https://migris.no/userguide/"
- MIGRI_USERNAME = "migrino"
- MIGRI_PASSWORD = "migri.no"

Miqlat
- http://www.miqlat.org/

MixMatch
- https://towardsdatascience.com/a-fastai-pytorch-implementation-of-mixmatch-314bb30d0f99
- https://github.com/google-research/mixmatch

ML YouTube Courses
- https://github.com/dair-ai/ML-YouTube-Courses

mlbox
- https://mlbox.readthedocs.io/en/latest/introduction.html

MobaXterm
- https://mobaxterm.mobatek.net/download.html
- Running powerful Unix CLI on Windows

Multi-Scale Rock Physics Research Program
- https://sites.utexas.edu/ultrapetrophysics/
- https://iap.cpge.utexas.edu/msrp/msrp2020.html
- https://iap.cpge.utexas.edu/msrp/msrp2021.html 
- (The user name is: UltraPetrophysics-2021, Password is: MultiScale.21)

Mwiti, Derrick
- https://cnvrg.io/hyperparameter-tuning/
- https://cnvrg.io/author/derrickm/

Naked Bible Podcast
- https://nakedbiblepodcast.com/

NDR UK
- NDR_UK_URL = "https://ndr.ogauthority.co.uk/"
- NDR_UK_USERNAME = "inp@equinor.com"
- NDR_UK_PASSWORD = "std"

neptune
- https://docs.neptune.ai/getting-started/hello-world

NET Bible
- https://netbible.org/bible/Matthew+1   

NIPS
- Advances in Neural Information Processing Systems 33 (NeurIPS 2020)
- Advances in Neural Information Processing Systems 32 (NeurIPS 2019)
- Advances in Neural Information Processing Systems 31 (NeurIPS 2018)
- Advances in Neural Information Processing Systems 30 (NIPS 2017)
- Advances in Neural Information Processing Systems 29 (NIPS 2016)
- Advances in Neural Information Processing Systems 28 (NIPS 2015)
- Advances in Neural Information Processing Systems 27 (NIPS 2014)
- Advances in Neural Information Processing Systems 26 (NIPS 2013)
- Advances in Neural Information Processing Systems 25 (NIPS 2012)
- Advances in Neural Information Processing Systems 24 (NIPS 2011)
- Advances in Neural Information Processing Systems 23 (NIPS 2010)
- Advances in Neural Information Processing Systems 22 (NIPS 2009)
- Advances in Neural Information Processing Systems 21 (NIPS 2008)
- Advances in Neural Information Processing Systems 20 (NIPS 2007)
- Advances in Neural Information Processing Systems 19 (NIPS 2006)
- Advances in Neural Information Processing Systems 18 (NIPS 2005)
- Advances in Neural Information Processing Systems 17 (NIPS 2004)
- Advances in Neural Information Processing Systems 16 (NIPS 2003)
- Advances in Neural Information Processing Systems 15 (NIPS 2002)
- Advances in Neural Information Processing Systems 14 (NIPS 2001)
- Advances in Neural Information Processing Systems 13 (NIPS 2000)
- Advances in Neural Information Processing Systems 12 (NIPS 1999)
- Advances in Neural Information Processing Systems 11 (NIPS 1998)
- Advances in Neural Information Processing Systems 10 (NIPS 1997)
- Advances in Neural Information Processing Systems 9 (NIPS 1996)
- Advances in Neural Information Processing Systems 8 (NIPS 1995)
- Advances in Neural Information Processing Systems 7 (NIPS 1994)
- Advances in Neural Information Processing Systems 6 (NIPS 1993)
- Advances in Neural Information Processing Systems 5 (NIPS 1992)
- Advances in Neural Information Processing Systems 4 (NIPS 1991)
- Advances in Neural Information Processing Systems 3 (NIPS 1990)
- Advances in Neural Information Processing Systems 2 (NIPS 1989)
- Advances in Neural Information Processing Systems 1 (NIPS 1988)

NMR
- https://rockphysicstechnology.com/

NPTEL
- https://www.youtube.com/c/iit/playlists
- https://nptel.ac.in/noc/noc_course.html

numpy

NVIDIA Developers Blog
- https://developer.nvidia.com/blog/

OBOS Bank, konto
- https://bank.obos.no/
Konto numm- er = 9820 32 83067

OBOS Bank, kort
- 4052 0800 2177 6530, 08/24, INGE HERMOD ASKL PETTERSEN, 469

ObsPy
- https://github.com/obspy/obspy/wiki
- seismology

ODSC Global slack
- https://app.slack.com/client/TKGLEV1LM/browse-channels

OPC
- https://open.spotify.com/show/17XrNFfClRRVP3s9ac5fpT

Open Data Science (OSDC) Categories
- https://opendatascience.com/category/academic-research/
- https://opendatascience.com/category/conferences/odsc-speaker/
- https://opendatascience.com/category/modeling/deep-learning/
- https://opendatascience.com/category/modeling/machine-learning/
- https://opendatascience.com/category/modeling/nlp-text-analytics/
- https://opendatascience.com/category/modeling/research-modeling/
- https://opendatascience.com/category/modeling/statistics/
- https://opendatascience.com/category/tools-languages/workflow/
- https://app.slack.com/client/TKGLEV1LM/learning-slack
- https://medium.com/odscjournal

Open Doors
- https://www.opendoors.no/

OpendTect
- https://dgbes.com/index.php/download

OpenKIM
- https://openkim.org/browse/models/alphabetical

Optimalization
- https://github.com/uber-research/TuRBO
- https://github.com/hyperopt/hyperopt
- https://scikit-optimize.github.io/stable/

OutWit Hub
- https://www.outwit.com/products/hub/OutWit-Hub-Light-Pro-Expert-Enterprise-editions

Packt
- https://subscription.packtpub.com/
- std passord

palabos; fluid flow
- https://palabos.unige.ch/
- https://gitlab.com/unigespc/palabos

pandas
- Pandas documentation
	https://pandas.pydata.org/pandas-docs/stable/
- Pandas source
	https://github.com/pandas-dev/pandas/tree/master/doc

pathlib

Penger.no
- https://penger.no

Pensjonistforbundet
- www.pensjonistforbundet.no
- Ditt medlemsnummer er 40292682 

People analytics regression book
- https://github.com/keithmcnulty/peopleanalytics-regression-book

petrophysics / predicting logs by ML
- https://towardsdatascience.com/prediction-of-p-sonic-log-in-the-volve-oil-field-using-machine-learning-9a4afdb92fe8
- https://towardsdatascience.com/petrophysics-gamma-ray-normalization-in-python-9a67a335dbd

Physics Informed DL
- https://maziarraissi.github.io/research/1_physics_informed_neural_networks/
- https://github.com/thunil/Physics-Based-Deep-Learning
- https://github.com/SciML/
- https://sciml.ai/

pickle
```python=
	import pickle
	est = SymbolicRegressor()
	est.fit(X_train, y_train)
	with open('gp_model.pkl', 'wb') as f:
	    pickle.dump(est, f)
	with open('gp_model.pkl', 'rb') as f:
	    est = pickle.load(f)
```

pillow

Pragmatic Bookshelf
- https://pragprog.com/

precipNet
- https://github.com/rmcgranaghan/precipNet
	
Privatdozent
- https://www.privatdozent.co/

Project Management
- Principles
	* https://coderefinery.github.io/reproducible-research/02-organizing-projects/
- Place for code
	* https://github.com:
	* https://gitlab.com: public or private repositories
	* https://source.coderefinery.org

PyCaret
- https://www.learndatasci.com/tutorials/introduction-pycaret-machine-learning/

PyData Global Talks
- https://courses.numfocus.org/courses/course-v1:PyDataGlobal+PDG20-talks+2020/about

pydotplus
```python=
	from IPython.display import Image
	import pydotplus
	graph = est_gp._program.export_graphviz()
	graph = pydotplus.graphviz.graph_from_dot_data(graph)
	Image(graph.create_png())
```

pylint

PySIT 
- http://pysit.readthedocs.io/en/stable/index.html
- seismic inversion

pytest
- API reference
- https://docs.pytest.org/en/6.2.x/reference.html

python idiom
```python=
l1, l2, ..., ln = ([] for _ in range(n))
```

python software carpentry, 10-11 Nov 2020
- https://www.youtube.com/playlist?list=PLpX1jXuNTXGoDO5vuHR_pSyxNBr_M233-

python-crontab 
- read and write crontab files

pythoncheatsheet
- https://www.pythoncheatsheet.org/

python for scientific computing
- https://aaltoscicomp.github.io/python-for-scicomp/

Python in Equinor
- https://statoilsrm.sharepoint.com/sites/InstallingPython/SitePages/Creating-virtual-environments.aspx
- Installing Python on Windows 
	* https://statoilsrm.sharepoint.com/sites/InstallingPython/SitePages/Installing-Python-Windows.aspx
- Installing additional Python packages on Windows
	* https://statoilsrm.sharepoint.com/sites/InstallingPython/SitePages/Installing-additional-Python-packages-on-Windows.aspx

Python Wiki
- https://wiki.python.org/moin/

pyttsx3
- https://pyttsx3.readthedocs.io/en/latest/

Quant Finance
- https://informaconnect.com/quant-finance/

Quantum Magazine - Biology
- https://www.quantamagazine.org/biology/
- https://www.quantamagazine.org/mathematics/
- https://www.quantamagazine.org/physics/

R Discovery
- R_Discovery_URL = "https://discovery.researcher.life/home"
- R_Discovery_USERNAME = "ingehap@gmail.com"
- R_Discovery_PASSWORD = "lillian7"

R Upskill
- you can manage your membership here 
- https://upskill.researcher.life/my-account/manage-subscription/  
- Plan type: R Upskill Membership – Monthly plan $9 

RealPython
- https://realpython.com
- https://realpython.com/start-contributing-python/
- https://realpython.com/python-sql-libraries/
- https://realpython.com/documenting-python-code/
- RealPython_URL = "https://realpython.com/"
- RealPython_USERNAME = "ingehap@gmail.com"
- RealPython_PASSWORD = "lillian7"

requests
- Requests documentation
- https://docs.python-requests.org/en/master/
- Requests source
- https://github.com/psf/requests/tree/master/docs

Research Bazar
- https://resbazblog.wordpress.com/

Research.com
- https://research.com/

Samordna Opptak
- https://www.samordnaopptak.no/info/

SaltNet
- https://library.seg.org/doi/abs/10.1190/tle39030195.1

Sbanken, kontoer
- Konto #1 - 9713 22 23 584 (Visa)
- Konto #2 - 9713 22 23 630

Sbanken, kort
- 4569 9710 6403 2482, INGE H. A. PETTERSEN, 04/24, 898

Schlumberger Curve Mnemonic Dictionary
- https://www.apps.slb.com/cmd/index.aspx

scipy

scopus
- SCOPUS_URL = "https://www.scopus.com/"
- SCOPUS_USERNAME = "inp@equinor.com"
- SCOPUS_PASSWORD = "lillian7"

Scotese
- http://www.scotese.com/sitemap.htm

script #1 template - basic

```python=

#!/usr/bin/env python
# python script template

def main():
    pass

if __name__ == "__main__":
    main()

```

script #2 template - slightly advanced

```python=
#!/usr/bin/env python

"""One-line description of what the script does.""" 

import argparse 

def main(args): 
    """Run the program.""" 
    print('Input file:', args.infile) 
    print('Output file:', args.outfile) 

if __name__ == '__main__': 
    parser = argparse.ArgumentParser(description=__doc__) 
    parser.add_argument('infile', type=str, help='Input file name') 
    parser.add_argument('outfile', type=str, help='Output file name') 
    args = parser.parse_args() 
    main(args)
```

SEG
- SEG eBooks
- https://library.seg.org/book/marc
- SEG Knowledgette
- https://www.knowledgette.com/courses/category/SEG
- SEG Lectures
- https://library.seg.org/e-learning/lectures
- SEG on Demand
- https://seg.org/Education/SEG-on-Demand
- SEG_URL = "https://seg.org/Default.aspx"
- SEG_USERNAME = "ingehap@gmail.com"
- SEG_PASSWORD = "Alle7Fugler8Smaa"

seg/tutorials-2018
- https://github.com/seg/tutorials-2018

Sequence
- https://thesequence.substack.com/archive

Serenity Prayer - Wikipedia
- https://en.wikipedia.org/wiki/Serenity_Prayer

ServiceNow Equinor Production System
- https://equinor.service-now.com/nav_to.do?uri=%2Ftask_list.do%3Fsysparm_userpref_module%3D1523b8d4c611227b00be8216ec331b9a%26sysparm_query%3Dactive%3Dtrue%5Eassigned_to%3Djavascript:getMyAssignments()%5EstateNOT%2BIN6,5%5EEQ%26sysparm_clear_stack%3Dtrue

SIAM
- User ID = 001019878
- Proc. 2021 SIAM Int. Conf. on Data Mining (SDM)
	https://epubs.siam.org/doi/book/10.1137/1.9781611976700
- SIAM Conferences on YouTube
	https://www.youtube.com/watch?v=1biep1Rh_08
- SIAM News
	https://sinews.siam.org/Current-Issue/Issue-Archives
- DL & PDE
	https://sinews.siam.org/Details-Page/new-bridges-between-deep-learning-and-partial-differential-equations

SILO closed Google Group
- https://groups.google.com/a/g-groups.wisc.edu/g/silo

site packages, list of search paths

```python=
	import site
	site.getsitepackages()
```

SlidesLive
- https://library.slideslive.com/

snakemake
- https://snakemake.readthedocs.io/en/stable/getting_started/installation.html

Software Sustainability Institute
- https://www.youtube.com/c/SoftwareSaved/playlists

SoloLearn
- https://www.sololearn.com/

Source Rock Machine Learning 
- https://github.com/equinor/SRML/

sphinx
- https://sphinx-tutorial.readthedocs.io/

SPWLA
- https://github.com/Amrmoslim/SPWLA_Webinar_Jan_2021
- https://github.com/SPWLA-ORG/spwla2021_ml_workshop
- https://github.com/zsylvester/meanderpy
- https://github.com/toddheitmann/petropy
- https://github.com/seg/2016-ml-contest
- https://github.com/brendonhall/FORCE-2020-Lithology
- https://www.youtube.com/channel/UCuY_meTb65lYmGSUNLzj-IA
- https://www.youtube.com/channel/UC4nGM9WrCaiZ3jQu9FzU2Sg
- https://github.com/pddasig
- SPWLA 2021 https://pheedloop.com/spwla2021/login/auth/?redirect=/spwla2021/virtual/ Email: ingehap@gmail.com   Password:gNpvfJncO@

Stack Abuse - Python
- https://stackabuse.com/tag/python/

Structure and Interpretation of Computer Programs
- http://sarabander.github.io/sicp/html/index.xhtml
- https://www.neilvandyke.org/sicp-texi/

Subsurface Excellence and Digital Communication Site
- https://statoilsrm.sharepoint.com/sites/subexd

TalkPython
- https://training.talkpython.fm/

ternary plot
- https://towardsdatascience.com/basics-of-ternary-plots-with-pythons-plotly-e5990ea399a5
- https://en.wikipedia.org/wiki/Ternary_plot
- https://plotly.com/python/ternary-plots/
- https://stackoverflow.com/questions/29512046/how-to-create-ternary-contour-plot-in-python

Theology
- https://en.wikipedia.org/wiki/Annihilationism
- https://en.wikipedia.org/wiki/Christian_conditionalism
- https://en.wikipedia.org/wiki/Christian_mortalism
- https://www.amazon.com/Julia-Blum/e/B00LUY0JN8

TheSequence
- https://thesequence.substack.com/archive

Towards AI
- https://pub.towardsai.net/

Tryo Labs
- https://tryolabs.com/blog/

TU Extra

TuringBot
- https://turingbotsoftware.com/blog/
- https://turingbotsoftware.com/

Uber engineering
- https://eng.uber.com/

Udemy
- https://www.udemy.com/

University of Bergen
- Theses @ Library, https://www.uib.no/en/ub

UTAPWeLS
- Equinor Wiki; https://wiki.equinor.com/wiki/index.php/Petrophysics:Software:UTAPWeLS
- YouTube; https://www.youtube.com/channel/UCHWnztyGyQPEXXbp2Tu0_DA/videos

voila 
- notebook as app

Weka
- https://www.cs.waikato.ac.nz/ml/weka/

Western Profile
- https://library.seg.org/page/western-profile

WikiProject Mathematics
- https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Mathematics

Wikipedia, Social psychology
- https://en.wikipedia.org/wiki/Social_psychology

WikiProject Statistics
- https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Statistics

World Wealth Report
- https://worldwealthreport.com

Wolfram Mathworld
- https://mathworld.wolfram.com/CatalansConstant.html

wrighters.io
- https://www.wrighters.io/parameters-jupyter-notebooks-with-papermill/?utm_campaign=Data_Elixir&utm_source=Data_Elixir_344
	
XEEK
- XEEK_URL = "https://xeek.ai/"
- XEEK_USERNAME = "inp@equinor.com"
- XEEK_PASSWORD = "Allefuglersmaa1!"



---> Scalars and vectors
scalar -> Location = Constant
log/vector -> Location = Input/Output

Finans nykommere
- korall engineering
- elopad, Ferd
- nacamed

Concepts
  - EBITDA = earnings before interest, tax, deprevation, amortization
  - Estimate = estimand + bias + noise
  - One-way door = decision difficult to reverse

Contact persons
  - Claussen, Stein Vidar; NMR, Baker
  - Maggs, David (maggs@slb.com); NPHI, SLB

Gas dynamics
  - GL0152 and GL0190

Geolog
  - geolog & pygg: pydoc documentation

Houston:
  - LithoScanner/Eagleford/XRD

Learning potetials
  - geoscience
    - Teeuw compaction correction (GB 3/15-10)
    - Forward modelling NPHI i Geolog i MM

Mathematics
  - experimental operations on integer sequences
  - forward shift etc.

En multilineær formulering av Tronds metode
  - bruk TVDML
  - produkt av potenser, linearisert ved logaritmer
  - sum lin av mulige ledd nCr

Quenscan
  - how does it work?

Rankings
  - Fortune 20xx Ranking
  - American Customer Satisfaction Index
  - UK Customer Satisfaction Index
  - LinkedIn's 20xx Top Companies
  - Reputation Quotient (Harris poll)

Data analysis
- what questions are answerable?
- understand the data
  - Bayes rule; P(M|D) = P(D|M) * P(M) / [ P(D|M)*P(M) + P(D|CM)*P(CM)]
  - logistic regression; P(favourite wins) = 1 / ( 1 + a * x**b); x = bet in uk format
  - confidence intervals; 95% NNormal distr is (mu - 1.96*s/str(n), mu + 1.96*s/str(n))
- modern data analysis
  - correlation
  - reward
  - learning
- build & evaluate models
  - Markov assumption
  - stationary distributions
  - stochastic DE

Paddy Power, Ladbrokers, William HillyRedbet, 888sport, Pinnacles, Matchbook


Barnekonvensjon vs foreldrerett i FN konvensjonen

Yammer: Arnstein Waldum, Alex Cullum, Geir Helgesen, Arild Eliassen, Anna Kullikova<br>

Aristoteles sine 4 årsakssammenhenger

Sverre Holm, ny bok

Sjekk ut SRML

Rydding

NordicBet blog
Mathematics Today
Current Biology
The Conversation
FourFourTwo

elitehat ofte relatert til moralkompetanse

effekt av kvartalsrapporter på kurs - før vs etter

eta = (epsilon - delta) / (1 + 2*delta)

Mathematical analysis
- asymtotic analysis
- homogenia\zation
- transformer(FFT, wavelets, Inverse Radon)

Datta analysis 
- Internal consistency check
- trends
- visualizations
- test hypotheses
- scale

Investering
- Har selskap kontroll på pris? (konkurrenter & tilbudsside)
- selskapets gjeld
- kostnadsside (effektiv drift, gammel organisasjon, kostnadsstruktur, konflikt/streik)
- nye konkurrenter
- inntekt (når tjeente sist, hvor mye, neste gang)



#---> Grids by lists

grid = [[f(i,j) for j in range(nb)] foor i in range(na)]

for i in range(na):
    for j in range(nb):
        g(i,j)

#---> Python libraries

https://github.com/microsoft/artifacts-keyring
https://github.com/equinor/well-log-qual
https://github.com/equinor/wellchart
https://github.com/equinor/seismod1d

#---> Make environments

conda env create -f env.yml
python3 -m venv .

#---> Pandas technique, merge dfs and save

df_total = pd.concat(list_of_df)
df_total.to_csv('.../all.csv')

#---> Numpy patterns; evaluate function on grid

x = np.array([-1, 0, 1])
y = np.array([-2, 0, 2])
X, Y = np.meshgrid(x, y)
Z = f(X, Y)

#---> sympy examples

from sympy import *
x = symbols('x')
f = x**2 + 1
plot(f)

from sympy import *
from sympy.plotting import plot3d
x, y = symbols('x y')
f = 2*x + 3*y
plot3d(f)

from sympy import *
i,n = symbols('i n')
summation = Sum(2*i,(i,1,n))
up_to_5 = summation.subs(n, 5)
print(up_to_5.doit()) # 30

from sympy import *
x = symbols('x')
expr = x**2 / x**5
print(expr) # x**(-3)

from math import log, exp
# 2 raised to what power gives me 8?
x = log(8, 2)
print(x) # prints 3.0

Desmos.com

from sympy import *
x = symbols('x')
f = 1 / x
result = limit(f, x, oo)
print(result) # 0

from sympy import *
n = symbols('n')
f = (1 + (1/n))**n
result = limit(f, n, oo)
print(result) # E
print(result.evalf()) # 2.71828182845905

def derivative_x(f, x, step_size):
    m = (f(x + step_size) - f(x)) / ((x + step_size) - x)
    return m

from sympy import *
x = symbols('x')
f = x**2
dx_f = diff(f)
print(dx_f) # prints 2*x

from sympy import *
from sympy.plotting import plot3d
x,y = symbols('x y')
f = 2*x**3 + 3*y**3
dx_f = diff(f, x)
dy_f = diff(f, y)
print(dx_f) # prints 6*x**2
print(dy_f) # prints 9*y**2
plot3d(f)

from sympy import *
x, s = symbols('x s')
f = x**2
slope_f = (f.subs(x, x + s) - f) / ((x+s) - x)
result = limit(slope_f, s, 0)
print(result) # 2x

from sympy import *
z = (x**2 + 1)**3 - 2
dz_dx = diff(z, x)
print(dz_dx)
# 6*x*(x**2 + 1)**2

from sympy import *
x, y = symbols('x y')
# derivative for first function
# need to underscore y to prevent variable clash
_y = x**2 + 1
dy_dx = diff(_y)
# derivative for second function
z = y**3 - 2
dz_dy = diff(z)
# Calculate derivative with and without
# chain rule, substitute y function
dz_dx_chain = (dy_dx * dz_dy).subs(y, _y)
dz_dx_no_chain = diff(z.subs(y, _y))
# Prove chain rule by showing both are equal
print(dz_dx_chain) # 6*x*(x**2 + 1)**2
print(dz_dx_no_chain) # 6*x*(x**2 + 1)**2

def approximate_integral(a, b, n, f):
    delta_x = (b - a) / n
    total_sum = 0
    for i in range(1, n + 1):
        midpoint = 0.5 * (2 * a + delta_x * (2 * i - 1))
        total_sum += f(midpoint)
    return total_sum * delta_x
def my_function(x):
    return x**2 + 1
area = approximate_integral(a=0, b=1, n=5, f=my_function)
print(area) # prints 1.33

from sympy import *
# Declare 'x' to SymPy
x = symbols('x')
# Now just use Python syntax to declare function
f = x**2 + 1
# Calculate the integral of the function with respect to x
# for the area between x = 0 and 1
area = integrate(f, (x, 0, 1))
print(area) # prints 4/3

from sympy import *
# Declare variables to SymPy
x, i, n = symbols('x i n')
# Declare function and range
f = x**2 + 1
lower, upper = 0, 1
# Calculate width and each rectangle height at index "i"
delta_x = ((upper - lower) / n)
x_i = (lower + delta_x * i)
fx_i = f.subs(x, x_i)
# Iterate all "n" rectangles and sum their areas
n_rectangles = Sum(delta_x * fx_i, (i, 1, n)).doit()
# Calculate the area by approaching the number
# of rectangles "n" to infinity
area = limit(n_rectangles, n, oo)
print(area) # prints 4/3

from scipy.stats import beta
a = 8
b = 2
p = beta.cdf(.90, a, b)
# 0.7748409780000001
print(p)

Bayesian Statistics the Fun Way by Will Kurt (No Starch Press).

# Three exams of .20 weight each and final exam of .40 weight
sample = [90, 80, 63, 87]
weights = [1.0, 1.0, 1.0, 2.0]
weighted_mean = sum(s * w for s,w in zip(sample, weights)) / sum(weights)
print(weighted_mean) # prints 81.4

# Number of pets each person owns
sample = [0, 1, 5, 7, 9, 10, 14]
def median(values):
    ordered = sorted(values)
    print(ordered)
    n = len(ordered)
    mid = int(n / 2) - 1 if n % 2 == 0 else int(n/2)
    if n % 2 == 0:
        return (ordered[mid] + ordered[mid+1]) / 2.0
    else:
        return ordered[mid]
print(median(sample)) # prints 7

# Number of pets each person owns
from collections import defaultdict
sample = [1, 3, 2, 5, 7, 0, 2, 3]
def mode(values):
    counts = defaultdict(lambda: 0)
    for s in values:
        counts[s] += 1
    max_count = max(counts.values())
    modes = [v for v in set(values) if counts[v] == max_count]
    return modes
print(mode(sample)) # [2, 3]

# Number of pets each person owns
from collections import defaultdict
sample = [1, 3, 2, 5, 7, 0, 2, 3]
def mode(values):
    counts = defaultdict(lambda: 0)
    for s in values:
        counts[s] += 1
    max_count = max(counts.values())
    modes = [v for v in set(values) if counts[v] == max_count]
    return modes
print(mode(sample)) # [2, 3]

from math import sqrt
# Number of pets each person owns
data = [0, 1, 5, 7, 9, 10, 14]
def variance(values, is_sample: bool = False):
    mean = sum(values) / len(values)
    _variance = sum((v - mean) ** 2 for v in values) /
      (len(values) - (1 if is_sample else 0))
    return _variance
def std_dev(values, is_sample: bool = False):
    return sqrt(variance(values, is_sample))
print("VARIANCE = {}".format(variance(data, is_sample=True))) # 24.95238095238095
print("STD DEV = {}".format(std_dev(data, is_sample=True))) # 4.99523582550223

# normal distribution, returns likelihood
def normal_pdf(x: float, mean: float, std_dev: float) -> float:
    return (1.0 / (2.0 * math.pi * std_dev ** 2) ** 0.5) *
        math.exp(-1.0 * ((x - mean) ** 2 / (2.0 * std_dev ** 2)))
        
from scipy.stats import norm
mean = 64.43
std_dev = 2.99
x = norm.cdf(64.43, mean, std_dev)
print(x) # prints 0.5

from scipy.stats import norm
x = norm.ppf(.95, loc=64.43, scale=2.99)
print(x) # 69.3481123445849

import random
from scipy.stats import norm
for i in range(0,1000):
    random_p = random.uniform(0.0, 1.0)
    random_weight = norm.ppf(random_p,  loc=64.43, scale=2.99)
    print(random_weight)

def z_score(x, mean, std):
    return (x - mean) / std
def z_to_x(z, mean, std):
    return (z * std) + mean
mean = 140000
std_dev = 3000
x = 150000
# Convert to Z-score and then back to X
z = z_score(x, mean, std_dev)
back_to_x = z_to_x(z, mean, std_dev)
print("Z-Score: {}".format(z))  # Z-Score: 3.333
print("Back to X: {}".format(back_to_x))  # Back to X: 150000.0

# Samples of the uniform distribution will average out to a normal distribution.
import random
import plotly.express as px
sample_size = 31
sample_count = 1000
# Central limit theorem, 1000 samples each with 31
# random numbers between 0.0 and 1.0
x_values = [(sum([random.uniform(0.0, 1.0) for i in range(sample_size)]) / \
    sample_size)
            for _ in range(sample_count)]
y_values = [1 for _ in range(sample_count)]
px.histogram(x=x_values, y = y_values, nbins=20).show()

from math import sqrt
from scipy.stats import norm
def critical_z_value(p):
    norm_dist = norm(loc=0.0, scale=1.0)
    left_tail_area = (1.0 - p) / 2.0
    upper_area = 1.0 - ((1.0 - p) / 2.0)
    return norm_dist.ppf(left_tail_area), norm_dist.ppf(upper_area)
def confidence_interval(p, sample_mean, sample_std, n):
    # Sample size must be greater than 30
    lower, upper = critical_z_value(p)
    lower_ci = lower * (sample_std / sqrt(n))
    upper_ci = upper * (sample_std / sqrt(n))
    return sample_mean + lower_ci, sample_mean + upper_ci
print(confidence_interval(p=.95, sample_mean=64.408, sample_std=2.05, n=31))
# (63.68635915701992, 65.12964084298008)

from scipy.stats import t
# get critical value range for 95% confidence
# with a sample size of 25
n = 25
lower = t.ppf(.025, df=n-1)
upper = t.ppf(.975, df=n-1)
print(lower, upper)
-2.063898561628021 2.0638985616280205

Gary Smith’s book Standard Deviations (Overlook Press).

Python PuLP use linear programming

from numpy import array
# Declare i-hat and j-hat
i_hat = array([2, 3])
j_hat = array([2, -1])
# compose basis matrix using i-hat and j-hat
# also need to transpose rows into columns
basis = array([i_hat, j_hat]).transpose()
# declare vector v 0
v = array([2,1])
# create new vector
# by transforming v with dot product
new_v = basis.dot(v)
print(new_v) # [6, 5]

from numpy import array
# Transformation 1
i_hat1 = array([0, 1])
j_hat1 = array([-1, 0])
transform1 = array([i_hat1, j_hat1]).transpose()
# Transformation 2
i_hat2 = array([1, 0])
j_hat2 = array([1, 1])
transform2 = array([i_hat2, j_hat2]).transpose()
# Combine Transformations
combined = transform2 @ transform1
# Test
print("COMBINED MATRIX:\n {}".format(combined))
v = array([1, 2])
print(combined.dot(v))  # [-1, 1]

from numpy.linalg import det
from numpy import array
i_hat = array([3, 0])
j_hat = array([0, 2])
basis = array([i_hat, j_hat]).transpose()
determinant = det(basis)
print(determinant) # prints 6.0

from sympy import *
# 4x + 2y + 4z = 44
# 5x + 3y + 7z = 56
# 9x + 3y + 6z = 72
A = Matrix([
    [4, 2, 4],
    [5, 3, 7],
    [9, 3, 6]
])
# dot product between A and its inverse
# will produce identity function
inverse = A.inv()
identity = inverse * A
# prints Matrix([[-1/2, 0, 1/3], [11/2, -2, -4/3], [-2, 1, 1/3]])
print("INVERSE: {}".format(inverse))
# prints Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])
print("IDENTITY: {}".format(identity))

from numpy import array
from numpy.linalg import inv
# 4x + 2y + 4z = 44
# 5x + 3y + 7z = 56
# 9x + 3y + 6z = 72
A = array([
    [4, 2, 4],
    [5, 3, 7],
    [9, 3, 6]
])
B = array([
    44,
    56,
    72
])
X = inv(A).dot(B)
print(X) # [ 2. 34. -8.]

from sympy import *
# 4x + 2y + 4z = 44
# 5x + 3y + 7z = 56
# 9x + 3y + 6z = 72
A = Matrix([
    [4, 2, 4],
    [5, 3, 7],
    [9, 3, 6]
])
B = Matrix([
    44,
    56,
    72
])
X = A.inv() * B
print(X) # Matrix([[2], [34], [-8]])

from numpy import array, diag
from numpy.linalg import eig, inv
A = array([
    [1, 2],
    [4, 5]
])
eigenvals, eigenvecs = eig(A)
print("EIGENVALUES")
print(eigenvals)
print("\nEIGENVECTORS")
print(eigenvecs)
"""
EIGENVALUES
[-0.46410162  6.46410162]

EIGENVECTORS
[[-0.80689822 -0.34372377]
 [ 0.59069049 -0.9390708 ]]
"""

from numpy import array, diag
from numpy.linalg import eig, inv
A = array([
    [1, 2],
    [4, 5]
])
eigenvals, eigenvecs = eig(A)
print("EIGENVALUES")
print(eigenvals)
print("\nEIGENVECTORS")
print(eigenvecs)
print("\nREBUILD MATRIX")
Q = eigenvecs
R = inv(Q)
L = diag(eigenvals)
B = Q @ L @ R
print(B)
"""
EIGENVALUES
[-0.46410162  6.46410162]

EIGENVECTORS
[[-0.80689822 -0.34372377]
 [ 0.59069049 -0.9390708 ]]

REBUILD MATRIX
[[1. 2.]
 [4. 5.]]
"""

book Python for Data Analysis (2nd edition) by Wes McKinney

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
# Import points
df = pd.read_csv('https://bit.ly/3goOAnt', delimiter=",")
# Extract input variables (all rows, all columns but last column)
X = df.values[:, :-1]
# Extract output column (all rows, last column)
Y = df.values[:, -1]
# Fit a line to the points
fit = LinearRegression().fit(X, Y)
# m = 1.7867224, b = -16.51923513
m = fit.coef_.flatten()
b = fit.intercept_.flatten()
print("m = {0}".format(m))
print("b = {0}".format(b))
# show in chart
plt.plot(X, Y, 'o') # scatterplot
plt.plot(X, m*X+b) # line
plt.show()

import pandas as pd
# Import points
points = pd.read_csv('https://bit.ly/3goOAnt', delimiter=",").itertuples()
# Test with a given line
m = 1.93939
b = 4.73333
# Calculate the residuals
for p in points:
    y_actual = p.y
    y_predict = m*p.x + b
    residual = y_actual - y_predict
    print(residual)

import pandas as pd
# Load the data
points = list(pd.read_csv('https://bit.ly/2KF29Bd', delimiter=",").itertuples())
n = len(points)
m = (n*sum(p.x*p.y for p in points) - sum(p.x for p in points) *
    sum(p.y for p in points)) / (n*sum(p.x**2 for p in points) -
    sum(p.x for p in points)**2)
b = (sum(p.y for p in points) / n) - m * sum(p.x for p in points) / n
print(m, b)
# 1.9393939393939394 4.7333333333333325

import pandas as pd
from numpy.linalg import inv
import numpy as np
# Import points
df = pd.read_csv('https://bit.ly/3goOAnt', delimiter=",")
# Extract input variables (all rows, all columns but last column)
X = df.values[:, :-1].flatten()
# Add placeholder "1" column to generate intercept
X_1 = np.vstack([X, np.ones(len(X))]).T
# Extract output column (all rows, last column)
Y = df.values[:, -1]
# Calculate coefficents for slope and intercept
b = inv(X_1.transpose() @ X_1) @ (X_1.transpose() @ Y)
print(b) # [1.93939394, 4.73333333]
# Predict against the y-values
y_predict = X_1.dot(b)

import pandas as pd
from numpy.linalg import qr, inv
import numpy as np
# Import points
df = pd.read_csv('https://bit.ly/3goOAnt', delimiter=",")
# Extract input variables (all rows, all columns but last column)
X = df.values[:, :-1].flatten()
# Add placeholder "1" column to generate intercept
X_1 = np.vstack([X, np.ones(len(X))]).transpose()
# Extract output column (all rows, last column)
Y = df.values[:, -1]
# calculate coefficents for slope and intercept
# using QR decomposition
Q, R = qr(X_1)
b = inv(R).dot(Q.transpose()).dot(Y)
print(b) # [1.93939394, 4.73333333]

import random
def f(x):
    return (x - 3) ** 2 + 4
def dx_f(x):
    return 2*(x - 3)
# The learning rate
L = 0.001
# The number of iterations to perform gradient descent
iterations = 100_000
# start at a random x
x = random.randint(-15,15)
for i in range(iterations):
    # get slope
    d_x = dx_f(x)
    # update x by subtracting the (learning rate) * (slope)
    x -= L * d_x
print(x, f(x)) # prints 2.999999999999889 4.0

from sympy import *
m, b, i, n = symbols('m b i n')
x, y = symbols('x y', cls=Function)
sum_of_squares = Sum((m*x(i) + b - y(i)) ** 2, (i, 0, n))
d_m = diff(sum_of_squares, m)
d_b = diff(sum_of_squares, b)
print(d_m)
print(d_b)
# OUTPUTS
# Sum(2*(b + m*x(i) - y(i))*x(i), (i, 0, n))
# Sum(2*b + 2*m*x(i) - 2*y(i), (i, 0, n))
import pandas as pd
# Import points from CSV
points = list(pd.read_csv("https://bit.ly/2KF29Bd").itertuples())
# Building the model
m = 0.0
b = 0.0
# The learning Rate
L = .001
# The number of iterations
iterations = 100_000
n = float(len(points))  # Number of elements in X
# Perform Gradient Descent
for i in range(iterations):
    # slope with respect to m
    D_m = sum(2 * p.x * ((m * p.x + b) - p.y) for p in points)
    # slope with respect to b
    D_b = sum(2 * ((m * p.x + b) - p.y) for p in points)
    # update m and b
    m -= L * D_m
    b -= L * D_b
print("y = {0}x + {1}".format(m, b))
# y = 1.9393939393939548x + 4.733333333333227

import pandas as pd
from sympy import *
# Import points from CSV
points = list(pd.read_csv("https://bit.ly/2KF29Bd").itertuples()
m, b, i, n = symbols('m b i n')
x, y = symbols('x y', cls=Function)
sum_of_squares = Sum((m*x(i) + b - y(i)) ** 2, (i, 0, n))
d_m = diff(sum_of_squares, m) \
    .subs(n, len(points) - 1).doit() \
    .replace(x, lambda i: points[i].x) \
    .replace(y, lambda i: points[i].y)
d_b = diff(sum_of_squares, b) \
    .subs(n, len(points) - 1).doit() \
    .replace(x, lambda i: points[i].x) \
    .replace(y, lambda i: points[i].y)
# compile using lambdify for faster computation
d_m = lambdify([m, b], d_m)
d_b = lambdify([m, b], d_b)
# Building the model
m = 0.0
b = 0.0
# The learning Rate
L = .001
# The number of iterations
iterations = 100_000
# Perform Gradient Descent
for i in range(iterations):
    # update m and b
    m -= d_m(m,b) * L
    b -= d_b(m,b) * L
print("y = {0}x + {1}".format(m, b))
# y = 1.939393939393954x + 4.733333333333231

from sympy import *
from sympy.plotting import plot3d
import pandas as pd
points = list(pd.read_csv("https://bit.ly/2KF29Bd").itertuples())
m, b, i, n = symbols('m b i n')
x, y = symbols('x y', cls=Function)
sum_of_squares = Sum((m*x(i) + b - y(i)) ** 2, (i, 0, n)) \
    .subs(n, len(points) - 1).doit() \
    .replace(x, lambda i: points[i].x) \
    .replace(y, lambda i: points[i].y)
plot3d(sum_of_squares)

import pandas as pd
import numpy as np
# Input data
data = pd.read_csv('https://bit.ly/2KF29Bd', header=0)
X = data.iloc[:, 0].values
Y = data.iloc[:, 1].values
n = data.shape[0]  # rows
# Building the model
m = 0.0
b = 0.0
sample_size = 1  # sample size
L = .0001  # The learning Rate
epochs = 1_000_000  # The number of iterations to perform gradient descent
# Performing Stochastic Gradient Descent
for i in range(epochs):
    idx = np.random.choice(n, sample_size, replace=False)
    x_sample = X[idx]
    y_sample = Y[idx]
    # The current predicted value of Y
    Y_pred = m * x_sample + b
    # d/dm derivative of loss function
    D_m = (-2 / sample_size) * sum(x_sample * (y_sample - Y_pred))
    # d/db derivative of loss function
    D_b = (-2 / sample_size) * sum(y_sample - Y_pred)
    m = m - L * D_m  # Update m
    b = b - L * D_b  # Update b
    # print progress
    if i % 10000 == 0:
        print(i, m, b)
print("y = {0}x + {1}".format(m, b))

import pandas as pd
# Read data into Pandas dataframe
df = pd.read_csv('https://bit.ly/2KF29Bd', delimiter=",")
# Print correlations between variables
correlations = df.corr(method='pearson')
print(correlations)
# OUTPUT:
#           x         y
# x  1.000000  0.957586
# y  0.957586  1.000000

import pandas as pd
from math import sqrt
# Import points from CSV
points = list(pd.read_csv("https://bit.ly/2KF29Bd").itertuples())
n = len(points)
numerator = n * sum(p.x * p.y for p in points) - \
            sum(p.x for p in points) * sum(p.y for p in points)
denominator = sqrt(n*sum(p.x**2 for p in points) - sum(p.x for p in points)**2) \
              * sqrt(n*sum(p.y**2 for p in points) - sum(p.y for p in points)**2)
corr = numerator / denominator
print(corr)
# OUTPUT:
# 0.9575860952087218

https://www.statsmodels.org/stable/regression.html

from scipy.stats import t
n = 10
lower_cv = t(n-1).ppf(.025)
upper_cv = t(n-1).ppf(.975)
print(lower_cv, upper_cv)
# -2.262157162740992 2.2621571627409915

from scipy.stats import t
from math import sqrt
# sample size
n = 10
lower_cv = t(n-1).ppf(.025)
upper_cv = t(n-1).ppf(.975)
# correlation coefficient
# derived from data https://bit.ly/2KF29Bd
r = 0.957586
# Perform the test
test_value = r / sqrt((1-r**2) / (n-2))
print("TEST VALUE: {}".format(test_value))
print("CRITICAL RANGE: {}, {}".format(lower_cv, upper_cv))
if test_value < lower_cv or test_value > upper_cv:
    print("CORRELATION PROVEN, REJECT H0")
else:
    print("CORRELATION NOT PROVEN, FAILED TO REJECT H0 ")
# Calculate p-value
if test_value > 0:
    p_value = 1.0 - t(n-1).cdf(test_value)
else:
    p_value = t(n-1).cdf(test_value)
# Two-tailed, so multiply by 2
p_value = p_value * 2
print("P-VALUE: {}".format(p_value))

import pandas as pd
# Read data into Pandas dataframe
df = pd.read_csv('https://bit.ly/2KF29Bd', delimiter=",")
# Print correlations between variables
coeff_determination = df.corr(method='pearson') ** 2
print(coeff_determination)
# OUTPUT:
#           x         y
# x  1.000000  0.916971
# y  0.916971  1.000000

import pandas as pd
from math import sqrt
# Load the data
points = list(pd.read_csv('https://bit.ly/2KF29Bd', delimiter=",").itertuples())
n = len(points)
# Regression line
m = 1.939
b = 4.733
# Calculate Standard Error of Estimate
S_e = sqrt((sum((p.y - (m*p.x +b))**2 for p in points))/(n-2))
print(S_e)
# 1.87406793500129

import pandas as pd
from scipy.stats import t
from math import sqrt
# Load the data
points = list(pd.read_csv('https://bit.ly/2KF29Bd', delimiter=",").itertuples())
n = len(points)
# Linear Regression Line
m = 1.939
b = 4.733
# Calculate Prediction Interval for x = 8.5
x_0 = 8.5
x_mean = sum(p.x for p in points) / len(points)
t_value = t(n - 2).ppf(.975)
standard_error = sqrt(sum((p.y - (m * p.x + b)) ** 2 for p in points) / (n - 2))
margin_of_error = t_value * standard_error * \
                  sqrt(1 + (1 / n) + (n * (x_0 - x_mean) ** 2) / \
                       (n * sum(p.x ** 2 for p in points) - \
                            sum(p.x for p in points) ** 2))
predicted_y = m*x_0 + b
# Calculate prediction interval
print(predicted_y - margin_of_error, predicted_y + margin_of_error)
# 16.462516875955465 25.966483124044537

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
# Load the data
df = pd.read_csv('https://bit.ly/3cIH97A', delimiter=",")
# Extract input variables (all rows, all columns but last column)
X = df.values[:, :-1]
# Extract output column (all rows, last column)
Y = df.values[:, -1]
# Separate training and testing data
# This leaves a third of the data out for testing
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1/3)
model = LinearRegression()
model.fit(X_train, Y_train)
result = model.score(X_test, Y_test)
print("r^2: %.3f" % result)

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold, cross_val_score
df = pd.read_csv('https://bit.ly/3cIH97A', delimiter=",")
# Extract input variables (all rows, all columns but last column)
X = df.values[:, :-1]
# Extract output column (all rows, last column)\
Y = df.values[:, -1]
# Perform a simple linear regression
kfold = KFold(n_splits=3, random_state=7, shuffle=True)
model = LinearRegression()
results = cross_val_score(model, X, Y, cv=kfold)
print(results)
print("MSE: mean=%.3f (stdev-%.3f)" % (results.mean(), results.std()))

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score, ShuffleSplit
df = pd.read_csv('https://bit.ly/38XwbeB', delimiter=",")
# Extract input variables (all rows, all columns but last column)
X = df.values[:, :-1]
# Extract output column (all rows, last column)\
Y = df.values[:, -1]
# Perform a simple linear regression
kfold = ShuffleSplit(n_splits=10, test_size=.33, random_state=7)
model = LinearRegression()
results = cross_val_score(model, X, Y, cv=kfold)
print(results)
print("mean=%.3f (stdev-%.3f)" % (results.mean(), results.std()))

import pandas as pd
from sklearn.linear_model import LinearRegression
# Load the data
df = pd.read_csv('https://bit.ly/2X1HWH7', delimiter=",")
# Extract input variables (all rows, all columns but last column)
X = df.values[:, :-1]
# Extract output column (all rows, last column)\
Y = df.values[:, -1]
# Training
fit = LinearRegression().fit(X, Y)
# Print coefficients
print("Coefficients = {0}".format(fit.coef_))
print("Intercept = {0}".format(fit.intercept_))
print("z = {0} + {1}x + {2}y".format(fit.intercept_, fit.coef_[0], fit.coef_[1]))

import math
def predict_probability(x, b0, b1):
    p = 1.0 / (1.0 + math.exp(-(b0 + b1 * x)))
    return p

from sympy import *
b0, b1, x = symbols('b0 b1 x')
p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))
p = p.subs(b0,-2.823)
p = p.subs(b1, 0.620)
print(p)
plot(p)

import pandas as pd
from sklearn.linear_model import LogisticRegression
# Load the data
df = pd.read_csv('https://bit.ly/33ebs2R', delimiter=",")
# Extract input variables (all rows, all columns but last column)
X = df.values[:, :-1]
# Extract output column (all rows, last column)
Y = df.values[:, -1]
# Perform logistic regression
# Turn off penalty
model = LogisticRegression(penalty='none')
model.fit(X, Y)
# print beta1
print(model.coef_.flatten()) # 0.69267212
# print beta0
print(model.intercept_.flatten()) # -3.17576395

One of the more helpful texts I have found is Hands-On Machine Learning with 
Scikit-Learn, Keras, and TensorFlow by Aurélien Géron.

import math
import pandas as pd
patient_data = pd.read_csv('https://bit.ly/33ebs2R', delimiter=",").itertuples()
b0 = -3.17576395
b1 = 0.69267212
def logistic_function(x):
    p = 1.0 / (1.0 + math.exp(-(b0 + b1 * x)))
    return p
# Calculate the joint likelihood
joint_likelihood = 1.0
for p in patient_data:
    if p.y == 1.0:
        joint_likelihood *= logistic_function(p.x)
    elif p.y == 0.0:
        joint_likelihood *= (1.0 - logistic_function(p.x))
print(joint_likelihood) # 4.7911180221699105e-05

# Calculate the joint likelihood
joint_likelihood = 0.0
for p in patient_data:
    joint_likelihood += math.log(logistic_function(p.x) ** p.y * \
                                 (1.0 - logistic_function(p.x)) ** (1.0 - p.y))
joint_likelihood = math.exp(joint_likelihood)
joint_likelihood = Sum(log((1.0 / (1.0 + exp(-(b + m * x(i)))))**y(i) * \
   (1.0 - (1.0 / (1.0 + exp(-(b + m * x(i))))))**(1-y(i))), (i, 0, n))
   
from sympy import *
import pandas as pd
points = list(pd.read_csv("https://tinyurl.com/y2cocoo7").itertuples())
b1, b0, i, n = symbols('b1 b0 i n')
x, y = symbols('x y', cls=Function)
joint_likelihood = Sum(log((1.0 / (1.0 + exp(-(b0 + b1 * x(i))))) ** y(i) \
   * (1.0 - (1.0 / (1.0 + exp(-(b0 + b1 * x(i)))))) ** (1 - y(i))), (i, 0, n))
# Partial derivative for m, with points substituted
d_b1 = diff(joint_likelihood, b1) \
         .subs(n, len(points) - 1).doit() \
         .replace(x, lambda i: points[i].x) \
         .replace(y, lambda i: points[i].y)
# Partial derivative for m, with points substituted
d_b0 = diff(joint_likelihood, b0) \
         .subs(n, len(points) - 1).doit() \
         .replace(x, lambda i: points[i].x) \
         .replace(y, lambda i: points[i].y)
# compile using lambdify for faster computation
d_b1 = lambdify([b1, b0], d_b1)
d_b0 = lambdify([b1, b0], d_b0)
# Perform Gradient Descent
b1 = 0.01
b0 = 0.01
L = .01
for j in range(10_000):
    b1 += d_b1(b1, b0) * L
    b0 += d_b0(b1, b0) * L
print(b1, b0)
# 0.6926693075370812 -3.175751550409821

import pandas as pd
from sklearn.linear_model import LogisticRegression
employee_data = pd.read_csv("https://tinyurl.com/y6r7qjrp")
# grab independent variable columns
inputs = employee_data.iloc[:, :-1]
# grab dependent "did_quit" variable column
output = employee_data.iloc[:, -1]
# build logistic regression
fit = LogisticRegression(penalty='none').fit(inputs, output)
# Print coefficients:
print("COEFFICIENTS: {0}".format(fit.coef_.flatten()))
print("INTERCEPT: {0}".format(fit.intercept_.flatten()))
# Interact and test with new employee data
def predict_employee_will_stay(sex, age, promotions, years_employed):
    prediction = fit.predict([[sex, age, promotions, years_employed]])
    probabilities = fit.predict_proba([[sex, age, promotions, years_employed]])
    if prediction == [[1]]:
        return "WILL LEAVE: {0}".format(probabilities)
    else:
        return "WILL STAY: {0}".format(probabilities)
# Test a prediction
while True:
    n = input("Predict employee will stay or leave {sex},
        {age},{promotions},{years employed}: ")
    (sex, age, promotions, years_employed) = n.split(",")
    print(predict_employee_will_stay(int(sex), int(age), int(promotions),
          int(years_employed)))
          
from math import log, exp
import pandas as pd
patient_data = pd.read_csv('https://bit.ly/33ebs2R', delimiter=",").itertuples()
b0 = -3.17576395
b1 = 0.69267212
def logistic_function(x):
    p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))
    return p
# Sum the log-likelihoods
log_likelihood_fit = 0.0
for p in patient_data:
    if p.y == 1.0:
        log_likelihood_fit += log(logistic_function(p.x))
    elif p.y == 0.0:
        log_likelihood_fit += log(1.0 - logistic_function(p.x))
print(log_likelihood_fit) # -9.946161673231583

log_likelihood_fit = sum(log(logistic_function(p.x)) * p.y +
                         log(1.0 - logistic_function(p.x)) * (1.0 - p.y)
                         for p in patient_data)

import pandas as pd
from math import log, exp
patient_data = list(pd.read_csv('https://bit.ly/33ebs2R', delimiter=",") \
     .itertuples())
likelihood = sum(p.y for p in patient_data) / len(patient_data)
log_likelihood = 0.0
for p in patient_data:
    if p.y == 1.0:
        log_likelihood += log(likelihood)
    elif p.y == 0.0:
        log_likelihood += log(1.0 - likelihood)
print(log_likelihood) # -14.341070198709906

log_likelihood = sum(log(likelihood)*p.y + log(1.0 - likelihood)*(1.0 - p.y) \
   for p in patient_data)
   
import pandas as pd
from math import log, exp
patient_data = list(pd.read_csv('https://bit.ly/33ebs2R', delimiter=",") \
                                .itertuples())
# Declare fitted logistic regression
b0 = -3.17576395
b1 = 0.69267212
def logistic_function(x):
    p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))
    return p
# calculate the log likelihood of the fit
log_likelihood_fit = sum(log(logistic_function(p.x)) * p.y +
                         log(1.0 - logistic_function(p.x)) * (1.0 - p.y)
                         for p in patient_data)
# calculate the log likelihood without fit
likelihood = sum(p.y for p in patient_data) / len(patient_data)
log_likelihood = sum(log(likelihood) * p.y + log(1.0 - likelihood) * (1.0 - p.y) \
   for p in patient_data)
# calculate R-Square
r2 = (log_likelihood - log_likelihood_fit) / log_likelihood
print(r2)  # 0.306456105756576

import pandas as pd
from math import log, exp
from scipy.stats import chi2
patient_data = list(pd.read_csv('https://bit.ly/33ebs2R', delimiter=",").itertuples())
# Declare fitted logistic regression
b0 = -3.17576395
b1 = 0.69267212
def logistic_function(x):
    p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))
    return p
# calculate the log likelihood of the fit
log_likelihood_fit = sum(log(logistic_function(p.x)) * p.y +
                         log(1.0 - logistic_function(p.x)) * (1.0 - p.y)
                         for p in patient_data)
# calculate the log likelihood without fit
likelihood = sum(p.y for p in patient_data) / len(patient_data)
log_likelihood = sum(log(likelihood) * p.y + log(1.0 - likelihood) * (1.0 - p.y) \
                     for p in patient_data)
# calculate p-value
chi2_input = 2 * (log_likelihood_fit - log_likelihood)
p_value = chi2.pdf(chi2_input, 1) # 1 degree of freedom (n - 1)
print(p_value)  # 0.0016604875618753787

import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import KFold, cross_val_score
# Load the data
df = pd.read_csv("https://tinyurl.com/y6r7qjrp", delimiter=",")
X = df.values[:, :-1]
Y = df.values[:, -1]
# "random_state" is the random seed, which we fix to 7
kfold = KFold(n_splits=3, random_state=7, shuffle=True)
model = LogisticRegression(penalty='none')
results = cross_val_score(model, X, Y, cv=kfold)
print("Accuracy Mean: %.3f (stdev=%.3f)" % (results.mean(), results.std()))

import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
# Load the data
df = pd.read_csv('https://bit.ly/3cManTi', delimiter=",")
# Extract input variables (all rows, all columns but last column)
X = df.values[:, :-1]
# Extract output column (all rows, last column)\
Y = df.values[:, -1]
model = LogisticRegression(solver='liblinear')
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.33,
    random_state=10)
model.fit(X_train, Y_train)
prediction = model.predict(X_test)
"""
The confusion matrix evaluates accuracy within each category.
[[truepositives falsenegatives]
 [falsepositives truenegatives]]
The diagonal represents correct predictions,
so we want those to be higher
"""
matrix = confusion_matrix(y_true=Y_test, y_pred=prediction)
print(matrix)
# put Scikit_learn model here
results = cross_val_score(model, X, Y, cv=kfold, scoring='roc_auc')
print("AUC: %.3f (%.3f)" % (results.mean(), results.std()))
# AUC: 0.791 (0.051)

X, Y = ...
X_train, X_test, Y_train, Y_test =  \
   train_test_split(X, Y, test_size=.33, stratify=Y)
   
from sympy import *
# plot relu
x = symbols('x')
relu = Max(0, x)
plot(relu)

from sympy import *
# plot logistic
x = symbols('x')
logistic = 1 / (1 + exp(-x))
plot(logistic)

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
all_data = pd.read_csv("https://tinyurl.com/y2qmhfsr")
# Extract the input columns, scale down by 255
all_inputs = (all_data.iloc[:, 0:3].values / 255.0)
all_outputs = all_data.iloc[:, -1].values
# Split train and test data sets
X_train, X_test, Y_train, Y_test = train_test_split(all_inputs, all_outputs,
    test_size=1/3)
n = X_train.shape[0] # number of training records
# Build neural network with weights and biases
# with random initialization
w_hidden = np.random.rand(3, 3)
w_output = np.random.rand(1, 3)
b_hidden = np.random.rand(3, 1)
b_output = np.random.rand(1, 1)
# Activation functions
relu = lambda x: np.maximum(x, 0)
logistic = lambda x: 1 / (1 + np.exp(-x))
# Runs inputs through the neural network to get predicted outputs
def forward_prop(X):
    Z1 = w_hidden @ X + b_hidden
    A1 = relu(Z1)
    Z2 = w_output @ A1 + b_output
    A2 = logistic(Z2)
    return Z1, A1, Z2, A2
# Calculate accuracy
test_predictions = forward_prop(X_test.transpose())[3] # grab only output layer, A2
test_comparisons = np.equal((test_predictions >= .5).flatten().astype(int), Y_test)
accuracy = sum(test_comparisons.astype(int) / X_test.shape[0])
print("ACCURACY: ", accuracy)

